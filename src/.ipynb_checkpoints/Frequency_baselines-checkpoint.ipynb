{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqUtils import CodonUsage\n",
    "from Bio.SeqUtils import IUPACData\n",
    "\n",
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.util import pad_sequence\n",
    "from nltk.util import bigrams\n",
    "from nltk.util import ngrams\n",
    "from nltk.util import everygrams\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.lm.preprocessing import flatten\n",
    "\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "bases = \"ATCG\"\n",
    "codons = [a + b + c for a in bases for b in bases for c in bases]\n",
    "codon_dict = {}\n",
    "for codon in codons:\n",
    "    codon_dict[codon] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_codon_dict = {}\n",
    "\n",
    "for codon in codons:\n",
    "    AA = str(Seq(codon).translate())\n",
    "    backward_codon_dict[AA] = []\n",
    "\n",
    "for codon in codons:\n",
    "    AA = str(Seq(codon).translate())\n",
    "    backward_codon_dict[AA].append(codon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoli_train = np.loadtxt(\"../data/data_split/ecoli_heg_train.txt\", dtype=\"str\")\n",
    "ecoli_test = np.loadtxt(\"../data/data_split/ecoli_heg_test.txt\", dtype=\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_triplet(seq):\n",
    "    ''' returns list of codons given NT sequence\n",
    "\n",
    "        Args:\n",
    "            str: NT sequence\n",
    "\n",
    "        Returns:\n",
    "            list: codons\n",
    "    '''\n",
    "    return [(seq[i:i+3]) for i in range(0, len(seq), 3)] \n",
    "\n",
    "def seqlist_to_triplets(seqs_NT):\n",
    "    ''' returns list of list of codons given list of NT sequences\n",
    "\n",
    "        Args:\n",
    "            list(str): NT sequences\n",
    "\n",
    "        Returns:\n",
    "            list(list(str)): list of list of codons\n",
    "    '''\n",
    "    return [seq_to_triplet(seq) for seq in seqs_NT]\n",
    "\n",
    "def NTlist_to_AA(seqs_NT):\n",
    "    ''' returns list of AA sequences given list of NT sequences\n",
    "\n",
    "        Args:\n",
    "            list(str): NT sequences\n",
    "\n",
    "        Returns:\n",
    "            list(str): list of AA sequences\n",
    "    '''\n",
    "    return [str(Seq(seq).translate()) for seq in seqs_NT]\n",
    "\n",
    "def pad_for_trigram(seqs):\n",
    "    ''' returns padded list of list of sequences for trigrams\n",
    "\n",
    "        Args:\n",
    "            list(str): list of AA sequences\n",
    "\n",
    "        Returns:\n",
    "            list(list(char)): list of list of AA sequences, each padded left and right by 1 <s>, </s>\n",
    "    '''\n",
    "    padded_seqs = []\n",
    "    for seq in seqs:\n",
    "        padded_seq = list(pad_sequence(seq, pad_left=True, left_pad_symbol=\"<s>\", \n",
    "                                    pad_right=True, right_pad_symbol=\"</s>\", n=2))\n",
    "        padded_seqs.append(padded_seq)\n",
    "        \n",
    "    return padded_seqs\n",
    "\n",
    "def pad_for_fivegram(seqs):\n",
    "    ''' returns padded list of list of sequences for fivegrams\n",
    "\n",
    "        Args:\n",
    "            list(str): list of AA sequences\n",
    "\n",
    "        Returns:\n",
    "            list(list(char)): list of list of AA sequences, each padded left and right by 2 <s>, </s>\n",
    "    '''\n",
    "    # we use adjusted_n = 2 for trigram, adjusted_n = 3 for 5 gram\n",
    "    padded_seqs = []\n",
    "    for seq in seqs:\n",
    "        padded_seq = list(pad_sequence(seq, pad_left=True, left_pad_symbol=\"<s>\", \n",
    "                                    pad_right=True, right_pad_symbol=\"</s>\", n=3))\n",
    "        padded_seqs.append(padded_seq)\n",
    "        \n",
    "    return padded_seqs\n",
    "\n",
    "def unigram_dictionary(seq_list):\n",
    "    ''' returns dictionary that maps unigram to most frequent codon\n",
    "\n",
    "        Args:\n",
    "            list(str): list of NT sequences\n",
    "\n",
    "        Returns:\n",
    "            dict(unigram:codon)\n",
    "    '''\n",
    "    seqs_AA = NTlist_to_AA(seq_list)\n",
    "    seqs_codon = seqlist_to_triplets(seq_list)\n",
    "    \n",
    "    unigram_dict = {}\n",
    "    \n",
    "    for i in range(len(seqs_AA)):\n",
    "        # this loop loops over the list of sequences\n",
    "        seq_codon = seqs_codon[i]\n",
    "        seq_AA_unigrams = list(ngrams(seqs_AA[i], n=1))\n",
    "        for j in range(len(seq_AA_unigrams)):\n",
    "            unigram = \"\".join(seq_AA_unigrams[j])\n",
    "            if unigram in unigram_dict:\n",
    "                unigram_dict[unigram].append(seq_codon[j])\n",
    "            else:\n",
    "                unigram_dict[unigram] = [seq_codon[j]]\n",
    "    \n",
    "    unigram_dict_frequency = {}\n",
    "    \n",
    "    for key in unigram_dict.keys():\n",
    "        codon_counter = Counter(unigram_dict[key])\n",
    "        total_count = 0\n",
    "        for codon_key in codon_counter:\n",
    "            total_count += codon_counter[codon_key]\n",
    "        \n",
    "        for codon_key in codon_counter:\n",
    "            codon_counter[codon_key] = codon_counter[codon_key] / total_count\n",
    "\n",
    "        unigram_dict_frequency[key] = codon_counter\n",
    "    \n",
    "    return unigram_dict_frequency\n",
    "\n",
    "def trigram_dictionary(seq_list):\n",
    "    seqs_AA = NTlist_to_AA(seq_list)\n",
    "    seqs_codon = seqlist_to_triplets(seq_list)\n",
    "    seqs_AA_padded = pad_for_trigram(seqs_AA)\n",
    "    \n",
    "    trigram_dict = {}\n",
    "    \n",
    "    for i in range(len(seqs_AA_padded)):\n",
    "        # this loop loops over the list of sequences\n",
    "        seq_codon = seqs_codon[i]\n",
    "        seq_AA_trigrams = list(ngrams(seqs_AA_padded[i], n=3))\n",
    "        for j in range(len(seq_AA_trigrams)):\n",
    "            trigram = \"\".join(seq_AA_trigrams[j])\n",
    "            if trigram in trigram_dict:\n",
    "                trigram_dict[trigram].append(seq_codon[j])\n",
    "            else:\n",
    "                trigram_dict[trigram] = [seq_codon[j]]\n",
    "    \n",
    "    trigram_dict_frequency = {}\n",
    "    \n",
    "    for key in trigram_dict.keys():\n",
    "        codon_counter = Counter(trigram_dict[key])\n",
    "        total_count = 0\n",
    "        for codon_key in codon_counter:\n",
    "            total_count += codon_counter[codon_key]\n",
    "        \n",
    "        for codon_key in codon_counter:\n",
    "            codon_counter[codon_key] = codon_counter[codon_key] / total_count\n",
    "\n",
    "        trigram_dict_frequency[key] = codon_counter\n",
    "    \n",
    "    return trigram_dict_frequency\n",
    "\n",
    "\n",
    "def fivegram_dictionary(seq_list):\n",
    "    seqs_AA = NTlist_to_AA(seq_list)\n",
    "    seqs_codon = seqlist_to_triplets(seq_list)\n",
    "    seqs_AA_padded = pad_for_fivegram(seqs_AA)\n",
    "    \n",
    "    fivegram_dict = {}\n",
    "    \n",
    "    for i in range(len(seqs_AA_padded)):\n",
    "        # this loop loops over the list of sequences\n",
    "        seq_codon = seqs_codon[i]\n",
    "        seq_AA_fivegrams = list(ngrams(seqs_AA_padded[i], n=5))\n",
    "        for j in range(len(seq_AA_fivegrams)):\n",
    "            fivegram = \"\".join(seq_AA_fivegrams[j])\n",
    "            if fivegram in fivegram_dict:\n",
    "                fivegram_dict[fivegram].append(seq_codon[j])\n",
    "            else:\n",
    "                fivegram_dict[fivegram] = [seq_codon[j]]\n",
    "    \n",
    "    fivegram_dict_frequency = {}\n",
    "    \n",
    "    for key in fivegram_dict.keys():\n",
    "        codon_counter = Counter(fivegram_dict[key])\n",
    "        total_count = 0\n",
    "        for codon_key in codon_counter:\n",
    "            total_count += codon_counter[codon_key]\n",
    "        \n",
    "        for codon_key in codon_counter:\n",
    "            codon_counter[codon_key] = codon_counter[codon_key] / total_count\n",
    "\n",
    "        fivegram_dict_frequency[key] = codon_counter\n",
    "    \n",
    "    return fivegram_dict_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train into train/val to figure out the weights\n",
    "ecoli_train_train, ecoli_train_test = train_test_split(ecoli_train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train frequency tables solely from the train set of train set\n",
    "unigram_frequency_dict = unigram_dictionary(ecoli_train_train)\n",
    "trigram_frequency_dict = trigram_dictionary(ecoli_train_train)\n",
    "fivegram_frequency_dict = fivegram_dictionary(ecoli_train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_codons(AA_seq, backward_codon_dict, unigram_frequency_dict, trigram_frequency_dict, fivegram_frequency_dict, a=1.0, b=1.0, c=1.0):\n",
    "    trigram_padded = list(pad_sequence(AA_seq, pad_left=True, left_pad_symbol=\"<s>\", \n",
    "                                    pad_right=True, right_pad_symbol=\"</s>\", n=2))\n",
    "    \n",
    "    fivegram_padded = list(pad_sequence(AA_seq, pad_left=True, left_pad_symbol=\"<s>\", \n",
    "                                    pad_right=True, right_pad_symbol=\"</s>\", n=3))\n",
    "    \n",
    "    unigrams = [\"\".join(ngram) for ngram in list(ngrams(AA_seq, n=1))]\n",
    "    trigrams = [\"\".join(ngram) for ngram in list(ngrams(trigram_padded, n=3))]\n",
    "    fivegrams = [\"\".join(ngram) for ngram in list(ngrams(fivegram_padded, n=5))]\n",
    "    \n",
    "    prediction_list = []\n",
    "    \n",
    "    for i in range(len(unigrams)): #loop over each AA in the sequence, generate a dictionary for each AA\n",
    "        \n",
    "        unigram = unigrams[i] #single amino acid at this position\n",
    "        trigram = trigrams[i] #3 amino acids concatenated at this position\n",
    "        fivegram = fivegrams[i] # 5 amino acids concatenated at this position\n",
    "        prediction = {} #dict that maps possible codon (not all 20) to frequency\n",
    "        \n",
    "        for codon in backward_codon_dict[unigram]: #loop over possible codons given AA\n",
    "            unigram_freq = 0.0\n",
    "            trigram_freq = 0.0\n",
    "            fivegram_freq = 0.0\n",
    "            \n",
    "            if unigram in unigram_frequency_dict and codon in unigram_frequency_dict[unigram]:\n",
    "                unigram_freq = unigram_frequency_dict[unigram][codon]\n",
    "                \n",
    "            if trigram in trigram_frequency_dict and codon in trigram_frequency_dict[trigram]:\n",
    "                trigram_freq = trigram_frequency_dict[trigram][codon]\n",
    "            \n",
    "            if fivegram in fivegram_frequency_dict and codon in fivegram_frequency_dict[fivegram]:\n",
    "                fivegram_freq = fivegram_frequency_dict[fivegram][codon]\n",
    "                \n",
    "                \n",
    "            prediction[codon] = a * unigram_freq + b * trigram_freq + c * fivegram_freq\n",
    "            \n",
    "        #softmax over possible codons    \n",
    "        prediction_list.append(softmax(list(prediction.values())))\n",
    "    \n",
    "    return prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(NT_seqs, backward_codon_dict, unigram_frequency_dict, trigram_frequency_dict, fivegram_frequency_dict, a=1.0, b=1.0, c=1.0):\n",
    "    AA_seqs = NTlist_to_AA(NT_seqs)\n",
    "    prediction_list = []\n",
    "    correct_list = []\n",
    "    loss = 0.0\n",
    "    \n",
    "    for AA_seq in AA_seqs:\n",
    "        for prediction in predict_codons(AA_seq, backward_codon_dict, unigram_frequency_dict, trigram_frequency_dict, fivegram_frequency_dict, a, b, c):\n",
    "            prediction_list.append(prediction)\n",
    "            \n",
    "    for NT_seq in NT_seqs:\n",
    "        codon_seq = seq_to_triplet(NT_seq)\n",
    "        for codon in codon_seq:\n",
    "            AA = str(Seq(codon).translate())\n",
    "\n",
    "            possible_codons = backward_codon_dict[AA]\n",
    "            target_codon_dict = {}\n",
    "            for possible_codon in possible_codons:\n",
    "                target_codon_dict[possible_codon] = 0.0\n",
    "                \n",
    "            target_codon_dict[codon] = 1.0\n",
    "            correct_list.append(list(target_codon_dict.values()))\n",
    "    \n",
    "#     print (prediction_list[:3])\n",
    "    \n",
    "    \n",
    "    for i in range(len(correct_list)):\n",
    "        print (correct_list[i])\n",
    "        print (prediction_list[i])\n",
    "        loss += log_loss(correct_list[i], prediction_list[i])\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0]\n",
      "[1.]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y_true contains only one label (1.0). Please provide the true labels explicitly through the labels argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-435-39c02430e06c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mecoli_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward_codon_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munigram_frequency_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrigram_frequency_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfivegram_frequency_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-434-f07bce19188e>\u001b[0m in \u001b[0;36mcalculate_loss\u001b[0;34m(NT_seqs, backward_codon_dict, unigram_frequency_dict, trigram_frequency_dict, fivegram_frequency_dict, a, b, c)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcorrect_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprediction_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/ML_env/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   1775\u001b[0m             raise ValueError('y_true contains only one label ({0}). Please '\n\u001b[1;32m   1776\u001b[0m                              \u001b[0;34m'provide the true labels explicitly through the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m                              'labels argument.'.format(lb.classes_[0]))\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             raise ValueError('The labels array needs to contain at least two '\n",
      "\u001b[0;31mValueError\u001b[0m: y_true contains only one label (1.0). Please provide the true labels explicitly through the labels argument."
     ]
    }
   ],
   "source": [
    "loss = calculate_loss(ecoli_train_test, backward_codon_dict, unigram_frequency_dict, trigram_frequency_dict, fivegram_frequency_dict, a=1.0, b=1.0, c=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = 10000000\n",
    "curr_w1 = 0\n",
    "curr_w2 = 0\n",
    "curr_w3 = 0\n",
    "\n",
    "for w1 in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    for w2 in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "        loss = calculate_loss(ecoli_train_test, backward_codon_dict, unigram_frequency_dict, trigram_frequency_dict, fivegram_frequency_dict, a=w1, b=w2, c=1.0-w1-w2)\n",
    "        if loss < min_loss:\n",
    "            min_loss = loss\n",
    "            curr_w1 = w1\n",
    "            curr_w2 = w2\n",
    "            curr_w3 = 1-w1-w2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GAG', 0.6666666666666666), ('GAA', 0.3333333333333333)]"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_frequency_dict['MEQ'].most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_trigram(ecoli_train, ecoli_test):\n",
    "    unigram_frequency_dict = unigram_dictionary(ecoli_train)\n",
    "    trigram_frequency_dict = trigram_dictionary(ecoli_train)\n",
    "    \n",
    "    AA_seqs = NTlist_to_AA(ecoli_test)\n",
    "    AA_seqs_padded = pad_for_trigram(AA_seqs)\n",
    "    codon_seqs = seqlist_to_triplets(ecoli_test)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i in range(len(AA_seqs_padded)):\n",
    "        AA_seq_trigrams = list(ngrams(AA_seqs_padded[i], n=3))\n",
    "        for j in range(len(AA_seq_trigrams)):\n",
    "            ngram_concat = \"\".join(AA_seq_trigrams[j])\n",
    "            total += 1\n",
    "            if ngram_concat in trigram_frequency_dict:\n",
    "                pred = trigram_frequency_dict[ngram_concat].most_common()[0][0]\n",
    "                if codon_seqs[i][j] == pred:\n",
    "                    correct += 1\n",
    "            else:\n",
    "                pred = unigram_frequency_dict[AA_seqs_padded[i][j+1]].most_common()[0][0]\n",
    "                if codon_seqs[i][j] == pred:\n",
    "                    correct += 1\n",
    "    \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_fivegram(ecoli_train, ecoli_test):\n",
    "    unigram_frequency_dict = unigram_dictionary(ecoli_train)\n",
    "    fivegram_frequency_dict = fivegram_dictionary(ecoli_train)\n",
    "    \n",
    "    AA_seqs = NTlist_to_AA(ecoli_test)\n",
    "    AA_seqs_padded = pad_for_fivegram(AA_seqs)\n",
    "    codon_seqs = seqlist_to_triplets(ecoli_test)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i in range(len(AA_seqs_padded)):\n",
    "        AA_seq_fivegrams = list(ngrams(AA_seqs_padded[i], n=5))\n",
    "        for j in range(len(AA_seq_fivegrams)):\n",
    "            ngram_concat = \"\".join(AA_seq_fivegrams[j])\n",
    "            total += 1\n",
    "            if ngram_concat in fivegram_frequency_dict:\n",
    "                pred = fivegram_frequency_dict[ngram_concat].most_common()[0][0]\n",
    "                if codon_seqs[i][j] == pred:\n",
    "                    correct += 1\n",
    "            else:\n",
    "                pred = unigram_frequency_dict[AA_seqs_padded[i][j+2]].most_common()[0][0]\n",
    "                if codon_seqs[i][j] == pred:\n",
    "                    correct += 1\n",
    "    \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6347405216456037"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy_trigram(ecoli_train, ecoli_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6232858295240656"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy_fivegram(ecoli_train, ecoli_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
