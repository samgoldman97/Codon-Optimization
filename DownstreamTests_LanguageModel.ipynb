{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XrvDAISh50tq"
   },
   "source": [
    "## CS287r Final Project\n",
    "## Language Model Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MtyuJBXJd_h3"
   },
   "source": [
    "## Install Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "qrtURpMz5wy2",
    "outputId": "0bf6acc8-3743-4a17-d27e-19f039dcc801"
   },
   "outputs": [],
   "source": [
    "# !pip install biopython\n",
    "!pip install -q torch torchtext opt_einsum\n",
    "!pip install -qU git+https://github.com/harvardnlp/namedtensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "Dfv_2I-3-j3o",
    "outputId": "f2555dd6-49d6-43b6-c973-b92e47377bbc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-2bdaaf8b-ed6c-40ba-9a1d-ea350e3a9a8d\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-2bdaaf8b-ed6c-40ba-9a1d-ea350e3a9a8d\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ecoli_CDS.fasta to ecoli_CDS.fasta\n"
     ]
    }
   ],
   "source": [
    "# ## Upload cds file..\n",
    "\n",
    "# #!wget -m ftp://ftp.ensemblgenomes.org/pub/release-43/bacteria//fasta/bacteria_0_collection/escherichia_coli_str_k_12_substr_mg1655/cdna/\n",
    "# #!mv ftp.ensemblgenomes.org/pub/release-43/bacteria/fasta/bacteria_0_collection/escherichia_coli_str_k_12_substr_mg1655/cdna/Escherichia_coli_str_k_12_substr_mg1655.ASM584v2.cdna.all.fa.gz ./ \n",
    "# #!unzip \"Escherichia_coli_str_k_12_substr_mg1655.ASM584v2.cdna.all.fa.gz\"\n",
    "\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_nJPkWqsys-u",
    "outputId": "699eaf4a-371a-4597-c0eb-2bf445ecfd3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat 'Escherichia_coli_str_k_12_substr_mg1655.ASM584v2.cdna.all.fa': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "mv Escherichia_coli_str_k_12_substr_mg1655.ASM584v2.cdna.all.fa ecoli_CDS.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EY3JqLxk50HJ"
   },
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqUtils import CodonUsage\n",
    "from Bio.SeqUtils import IUPACData\n",
    "import torch\n",
    "import torchtext\n",
    "from namedtensor import ntorch\n",
    "from namedtensor.text import NamedField\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.util import ngrams\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "# from google.colab import files\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "biBt0uYHeGU1"
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L53cBDAB50JR"
   },
   "outputs": [],
   "source": [
    "# Our input $x$\n",
    "# Prepend with a start token\n",
    "tokenize = lambda x : [\"<START>\"] + re.findall('.{%d}' % 3, x)\n",
    "TEXT = NamedField(names=(\"seqlen\", ), sequential=True, \n",
    "                  lower=True, tokenize=tokenize)\n",
    "AA_LABEL = NamedField(names=(\"seqlen\", ), \n",
    "                  lower=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yrQxUwLn50Lk"
   },
   "outputs": [],
   "source": [
    "# Note: Fairly round about way of getting this loaded into pytorch..\n",
    "# Wrangling data into format pytorch language prefers.. \n",
    "sequences = [str(rec.seq) for rec in SeqIO.parse(\"ecoli_CDS.fasta\", \"fasta\") if len(rec.seq) % 3 == 0]\n",
    "df = pd.DataFrame(sequences, columns=[\"sequence\"])\n",
    "df.to_csv(\"cds.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths = [len(sequences[i]) for i in range(len(sequences))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1355844.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(sequence_lengths)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(np.array(sequence_lengths), color=\"green\", bins=30, kde=False).set_title(\"Distribution of CDS length in E. coli\", fontsize=18)\n",
    "plt.savefig(\"CDS Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "XT72gjMkR5bj",
    "outputId": "1596470d-c1ee-4ccc-d2bf-f4d2f3170b3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<START>',\n",
       " 'GTG',\n",
       " 'TCA',\n",
       " 'CTT',\n",
       " 'TCG',\n",
       " 'CTT',\n",
       " 'TGG',\n",
       " 'CAG',\n",
       " 'CAG',\n",
       " 'TGT',\n",
       " 'CTT',\n",
       " 'GCC',\n",
       " 'CGA',\n",
       " 'TTG',\n",
       " 'CAG',\n",
       " 'GAT',\n",
       " 'GAG',\n",
       " 'TTA',\n",
       " 'CCA',\n",
       " 'GCC',\n",
       " 'ACA',\n",
       " 'GAA']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_ = [rec.seq for rec in SeqIO.parse(\"ecoli_CDS.fasta\", \"fasta\") if len(rec.seq) % 3 == 0]\n",
    "tokenize(str(sequences_[0][:21*3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NXgf0rBVWDCO"
   },
   "outputs": [],
   "source": [
    "#generate all DNA triplets\n",
    "bases = \"tcag\"\n",
    "codons = [a + b + c for a in bases for b in bases for c in bases]\n",
    "aa = [str(Seq(j).translate()) for j in codons]\n",
    "codon_to_aa = dict(zip(codons, aa))\n",
    "\n",
    "\n",
    "#create one hot of AA encoding\n",
    "AA_LABEL.build_vocab(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-p--2rJY50OE"
   },
   "outputs": [],
   "source": [
    "my_data = torchtext.data.TabularDataset(\"cds.csv\", format=\"CSV\", \n",
    "                                        fields=[(\"sequence\", TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5O0OCHykEUtu"
   },
   "outputs": [],
   "source": [
    "train, test = my_data.split(split_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5aoF2rKyM6FF"
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBEAtnKJUjwg"
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator, BucketIterator\n",
    " \n",
    "#we don't split genes\n",
    "train_iter_bucket, test_iter_bucket = torchtext.data.BucketIterator.splits(\n",
    "    (train, test), batch_sizes=(10,10), sort_within_batch=False, sort_key=lambda x : len(x.sequence),\n",
    "    device=torch.device(device, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ib9xVCdgGq6"
   },
   "outputs": [],
   "source": [
    "# Make a look up table, such that you can index with the vocab item (e.g. a codon)\n",
    "# and get the one hot corresponding to its amino acid\n",
    "one_hot_vec = torch.eye(len(AA_LABEL.vocab))\n",
    "zero_vec =  torch.zeros(len(AA_LABEL.vocab), 1)\n",
    "direct_look_up = [one_hot_vec[AA_LABEL.vocab.stoi[codon_to_aa[TEXT.vocab.itos[i]]]].unsqueeze(1) \n",
    "                  if TEXT.vocab.itos[i] in codon_to_aa else zero_vec\n",
    "                  for i in range(len(TEXT.vocab.stoi))]\n",
    "\n",
    "# Codon x one hot \n",
    "index_table = torch.cat(direct_look_up, dim=1).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9qbFSWzAzFJF"
   },
   "outputs": [],
   "source": [
    "####\n",
    "\n",
    "# TEXT.vocab.itos[x]: retrieves codon given numbering in the order of "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "94Bv7I2y1XuI"
   },
   "source": [
    "\n",
    "TEXT.vocab.itos[num]: retrieves codon given numbering in the encoding position\n",
    "\n",
    "TEXT.vocab.stoi[\"gaa\"]: retrieves encoding given codon\n",
    "\n",
    "codon_to_aa: dictionary. key: codon, val: AA\n",
    "\n",
    "AA_LABEL.vocab.stoi[AA]: retrieves AA encoding given AA\n",
    "AA_LABEL.vocab.itos[num]: retrieves AA given AA encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AA_LABEL.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4s1Vg9grfRV2"
   },
   "outputs": [],
   "source": [
    "codon_to_aa_index = torch.argmax(index_table, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "zugdkAQUEp8k",
    "outputId": "390fbf8c-1de5-4785-8664-ad0565057a50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codon_embed = TEXT.vocab.stoi[\"aat\"]\n",
    "print(codon_embed)\n",
    "\n",
    "# One hot of amino acid embedding\n",
    "index_table[codon_embed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfWyJa0MM6rx"
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_iter_bucket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pVoYFxtCJuy4",
    "outputId": "ad207fca-6f0b-440c-dce3-6d21347ce90d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('batch', 10), ('seqlen', 702), ('onehot', 23)])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = ntorch.nn.Embedding.from_pretrained(index_table).spec(\"seqlen\", \"onehot\").to(device)\n",
    "embed(batch.sequence).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4WxprVRmL_H0"
   },
   "outputs": [],
   "source": [
    "# Build masking table\n",
    "# Here, if it's a synonymous option, give it 0 value, if not, give -1e9\n",
    "# Add this with the output vector (i.e. output += mask_tbl[trg]) before softmax\n",
    "mask_tbl = torch.tensor(np.array([[0 if (codon in codon_to_aa and codon_2 in codon_to_aa and codon_to_aa[codon] == codon_to_aa[codon_2]) else -1e9 \n",
    "           for codon_2 in TEXT.vocab.itos] \n",
    "          for index, codon in enumerate(TEXT.vocab.itos)])).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "EoNXvzAsGDwp",
    "outputId": "15b2e7b5-f806-4554-8177-022ea8997479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODON aaa aag\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,  0.0000e+00,\n",
       "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "        -1.0000e+09, -1.0000e+09,  0.0000e+00, -1.0000e+09, -1.0000e+09,\n",
       "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "        -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
       "        -1.0000e+09, -1.0000e+09], dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"CODON\", TEXT.vocab.itos[4], TEXT.vocab.itos[42])\n",
    "\n",
    "mask_tbl[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eT8A05zpMCQw",
    "outputId": "2d3e2212-2849-4039-e508-8c35adebf09c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2369\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 0\n",
    "for batch in train_iter_bucket:\n",
    "  if batch.sequence.shape[\"seqlen\"] > max_seq_len: \n",
    "    max_seq_len = batch.sequence.shape[\"seqlen\"] \n",
    "\n",
    "for batch in test_iter_bucket:\n",
    "  if batch.sequence.shape[\"seqlen\"] > max_seq_len: \n",
    "    max_seq_len = batch.sequence.shape[\"seqlen\"] \n",
    "\n",
    "print(max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O0qthAXLif_u"
   },
   "source": [
    "## Import Data (Character Level Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XbSKJ2tpiidg"
   },
   "outputs": [],
   "source": [
    "tokenize_char = lambda x : [\"<START>\"] + list(x)\n",
    "TEXT_CHAR = NamedField(names=(\"seqlen\", ), sequential=True, \n",
    "                  lower=True, tokenize=tokenize_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_ibXEWZiiTZ"
   },
   "outputs": [],
   "source": [
    "my_data_char = torchtext.data.TabularDataset(\"cds.csv\", format=\"CSV\", \n",
    "                                        fields=[(\"sequence\", TEXT_CHAR)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mbO1nVm2iiMk"
   },
   "outputs": [],
   "source": [
    "train_char, test_char = my_data_char.split(split_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MVyncPjojbJE"
   },
   "outputs": [],
   "source": [
    "TEXT_CHAR.build_vocab(train_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "colab_type": "code",
    "id": "myhHYBhzjbED",
    "outputId": "87e3ad02-da18-4d10-e129-9c95ab8ae35a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function torchtext.vocab._default_unk_index>,\n",
       "            {'<pad>': 1,\n",
       "             '<start>': 6,\n",
       "             '<unk>': 0,\n",
       "             'a': 5,\n",
       "             'c': 3,\n",
       "             'g': 2,\n",
       "             't': 4})"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT_CHAR.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Z1A1bsLja8_"
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator, BucketIterator\n",
    " \n",
    "#we don't split genes\n",
    "train_iter_char_bucket, test_iter_char_bucket = torchtext.data.BucketIterator.splits(\n",
    "    (train_char, test_char), batch_sizes=(10,10), sort_within_batch=False, sort_key=lambda x : len(x.sequence),\n",
    "    device=torch.device(device, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpCF952mmObK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "44j9g4zwmOUP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zBScOiR3UPNR"
   },
   "source": [
    "## Make frequency table for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qi6H086PURgd"
   },
   "outputs": [],
   "source": [
    "def count_codons_iter(train_iter):\n",
    "  ''' Calculate the counts of each codon given subset of a CDS\n",
    "  \n",
    "  Args:\n",
    "    Train iter\n",
    "    \n",
    "  Returns:\n",
    "    dict{str, int}: dictionary with codons as key and corresponding number of occurences\n",
    "  \n",
    "  '''\n",
    "  codons_dict = CodonUsage.CodonsDict.copy()\n",
    "  for i, batch in enumerate(train_iter):\n",
    "\n",
    "    # Select for all non zero tensors\n",
    "    # Use this to find all indices that aren't padding\n",
    "    seq_len = batch.sequence.shape[\"seqlen\"]\n",
    "    batch_size = batch.sequence.shape[\"batch\"]\n",
    "    seq = batch.sequence.detach().cpu().numpy()\n",
    "    for batch_item in range(batch_size): \n",
    "      for seq_item in range(0, seq_len):\n",
    "        word = seq[seq_item, batch_item]\n",
    "        if TEXT.vocab.itos[word] in codon_to_aa: \n",
    "          codons_dict[TEXT.vocab.itos[word].upper()] += 1\n",
    "        elif TEXT.vocab.itos[word] == \"<pad>\": \n",
    "          # Break loop if we are at padding...\n",
    "          seq_item = seq_len + 1\n",
    "          \n",
    "   \n",
    "  return codons_dict\n",
    "\n",
    "def count_codons_fasta(fasta_file):\n",
    "  ''' Calculate the counts of each codon given a set of CDS\n",
    "  \n",
    "  Args:\n",
    "    Fasta file \n",
    "    \n",
    "  Returns:\n",
    "    dict{str, int}: dictionary with codons as key and corresponding number of occurences\n",
    "  \n",
    "  '''\n",
    "  \n",
    "  codons_dict = CodonUsage.CodonsDict.copy()\n",
    "  \n",
    "  for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    seq = record.seq\n",
    "    if len(seq) % 3 != 0:\n",
    "      continue\n",
    "      \n",
    "    #count the codons for this sequence\n",
    "    for codon_start in range(0, len(seq), 3):\n",
    "      codons_dict[str(seq[codon_start:codon_start+3])] += 1\n",
    "   \n",
    "  return codons_dict\n",
    "\n",
    "def calculate_codon_frequency(codon_counts):\n",
    "  ''' Calculate the counts of each codon given a set of CDS\n",
    "  \n",
    "  Args:\n",
    "    codon usage table\n",
    "    \n",
    "  Returns:\n",
    "    dict{str, float}: dictionary with codons as key and corresponding \n",
    "    frequency of codon for AA\n",
    "  \n",
    "  '''\n",
    "  codon_freqs = CodonUsage.CodonsDict.copy()\n",
    "  \n",
    "  for _, synonymous_codons in CodonUsage.SynonymousCodons.items():\n",
    "    total_AA_count = sum([codon_counts[codon] for codon in synonymous_codons])\n",
    "    \n",
    "    if total_AA_count == 0:\n",
    "      continue\n",
    "      \n",
    "    for codon in synonymous_codons:\n",
    "      codon_freqs[codon] = codon_counts[codon] / total_AA_count\n",
    "  \n",
    "  return codon_freqs\n",
    "\n",
    "eColi_codon_counts = count_codons_fasta(\"ecoli_CDS.fasta\")\n",
    "# eColi_codon_counts = count_codons_iter(train_iter_bucket)\n",
    "eColi_codon_table = calculate_codon_frequency(eColi_codon_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aZmOIRRRr0Io"
   },
   "outputs": [],
   "source": [
    "def make_unigram_conversion(train_iter): \n",
    "  ''' Help make table... '''\n",
    "  eColi_codon_counts = count_codons_iter(train_iter)\n",
    "  eColi_codon_table = calculate_codon_frequency(eColi_codon_counts)\n",
    "  unigram_freq_tbl = torch.tensor(np.array([[eColi_codon_table[codon_2.upper()] if (codon in codon_to_aa and codon_2 in codon_to_aa and codon_to_aa[codon] == codon_to_aa[codon_2]) else 0 \n",
    "             for codon_2 in TEXT.vocab.itos] \n",
    "            for index, codon in enumerate(TEXT.vocab.itos)])).to(device)\n",
    "  \n",
    "  pad_index = TEXT.vocab.stoi[\"<pad>\"]\n",
    "  unigram_freq_tbl[pad_index,pad_index] = 1\n",
    "  return unigram_freq_tbl \n",
    "\n",
    "\n",
    "unigram_freq_tbl = make_unigram_conversion(train_iter_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kVb8Du80C0Z5"
   },
   "source": [
    "#### N gram frequency helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uMBilqW2wlyo"
   },
   "outputs": [],
   "source": [
    "def make_n_gram(train_iter, n, amino_acid_conversion):\n",
    "  '''\n",
    "  n : the number to each side...\n",
    "      e.g. 0 gram corresponds to freq, 1 gram corresponds to 3, etc.\n",
    "  amino_acid_conversion: tensor used to convert seq to AA one hots\n",
    "  '''\n",
    "  with torch.no_grad():\n",
    "    n_grams = []\n",
    "    targets = []\n",
    "    ident_mat = np.eye(len(TEXT.vocab.stoi))\n",
    "    ident_mat_aa = np.eye(len(AA_LABEL.vocab))\n",
    "    for i, batch in enumerate(train_iter):\n",
    "      # Select for all non zero tensors\n",
    "      # Use this to find all indices that aren't padding\n",
    "      seq_len = batch.sequence.shape[\"seqlen\"]\n",
    "      batch_size = batch.sequence.shape[\"batch\"]\n",
    "\n",
    "      # Pad amino acids and seq with <pad> token \n",
    "      pad_token = TEXT.vocab.stoi[\"<pad>\"]\n",
    "      additional_padding = ntorch.ones(batch_size, n, \n",
    "                                      names=(\"batch\", \"seqlen\")).long()\n",
    "      additional_padding *= pad_token\n",
    "      \n",
    "      seq = ntorch.cat([additional_padding, batch.sequence, additional_padding],\n",
    "                      dim=\"seqlen\")\n",
    "      \n",
    "      # Now one hots.. \n",
    "      amino_acids = amino_acid_conversion[seq.values].detach().cpu().numpy()\n",
    "      # Note: we should assert that start and pad are treated the same\n",
    "      # This is because at test time, presumably we narrow the start for the AA.. \n",
    "      if i == 0:\n",
    "        assert((amino_acids[0,n] == amino_acids[0,0]).all())\n",
    "      \n",
    "      seq = seq.detach().cpu().numpy()\n",
    "      # Pad with padding token\n",
    "      for batch_item in range(batch_size): \n",
    "        # start at n, end at seq_len - n\n",
    "        for seq_item in range(n, seq_len - n):\n",
    "          # Middle token is a discrete number representing the codon (0 to 66)\n",
    "          middle_token = seq[batch_item, seq_item]\n",
    "          # N gram is a 2d numpy array containing an amino acid embedding in each row\n",
    "          n_gram = amino_acids[batch_item,seq_item - n : seq_item + n + 1]\n",
    "          \n",
    "          # If we want all one hots:\n",
    "          # n_grams.append(ident_mat_aa[n_gram])\n",
    "          # targets.append(ident_mat[middle_token])\n",
    "\n",
    "          # If we want all indices:\n",
    "          n_grams.append(n_gram)\n",
    "          targets.append(middle_token)\n",
    "          \n",
    "  return n_grams, targets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_dictionary(n_grams, targets): \n",
    "  ''' Takes n grams and targets and makes them into '''\n",
    "  default_obj = lambda : torch.tensor(np.zeros(len(TEXT.vocab.stoi)))\n",
    "  default_dict = defaultdict(default_obj)\n",
    "  \n",
    "  for n_gram, target in zip(n_grams, targets): \n",
    "    default_dict[str(n_gram)][target] += 1\n",
    "    \n",
    "  for key in default_dict: \n",
    "    default_dict[key] /= (default_dict[key]).sum()\n",
    "    \n",
    "  return default_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "colab_type": "code",
    "id": "Vp0w6yso_kHz",
    "outputId": "80cc5d10-666a-4e89-900b-032330f5c7c8"
   },
   "outputs": [],
   "source": [
    "# n_grams are indices in amino acid space, targets are indices in codon space\n",
    "# n_grams, targets = make_n_gram(train_iter_bucket, 0, codon_to_aa_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RPMm5nyPWvvS"
   },
   "source": [
    "# Language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fIVy7J0ceLkA"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "caIqk_EOmaDc"
   },
   "source": [
    "### Codon Level Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZoA2XV9mivw"
   },
   "source": [
    "#### AA_COMPRESS\n",
    "A model to compress a codon sequence into its amino acid representation\n",
    "Can be easily used by passing in an embedding that turns each amino acid into a onehot OR each amino acid into a frequency table representation for its codon (unigram model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tl1h-vYXXQqE"
   },
   "outputs": [],
   "source": [
    "class AA_COMPRESS(ntorch.nn.Module):\n",
    "  '''\n",
    "  Compress info for codon sequence at the amino acid level\n",
    "  '''\n",
    "  \n",
    "  def __init__(self, params): \n",
    "    super(AA_COMPRESS, self).__init__()\n",
    "    self.codon_to_aa = params[\"CODON_TO_AA\"]\n",
    "    self.aa_embed = (ntorch.nn.Embedding.from_pretrained(self.codon_to_aa)\n",
    "                     .spec(\"seqlen\", \"hiddenlen\"))\n",
    "    \n",
    "    # don't learn these.. \n",
    "    self.aa_embed.weight.requires_grad_(False)  \n",
    "    \n",
    "  def forward(self, seq): \n",
    "    return self.aa_embed(seq)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4dPiQI0ddUaH"
   },
   "source": [
    "#### AA_NGRAM\n",
    "A model class that will take a string of codons and turn them into amino acids, then turn those amino acids into n gram based frequencies for what codon should be predicted in each position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nCYYQR2adxU7"
   },
   "outputs": [],
   "source": [
    "class AA_NGRAM(ntorch.nn.Module):\n",
    "  '''\n",
    "  Compress info for codon sequence at the amino acid level\n",
    "  TODO: Ignore pading predicts in forward pass to save time\n",
    "  '''\n",
    "  \n",
    "  def __init__(self, params): \n",
    "    super(AA_NGRAM, self).__init__()\n",
    "    self.codon_to_aa = params[\"CODON_TO_AA\"]\n",
    "    self.dict_list = params[\"N_GRAM_DICTS\"]\n",
    "    # How many indcies each dict takes\n",
    "    self.n_list = params[\"N_LIST\"]\n",
    "    # probability to apply to each n gram used\n",
    "    self.weight_list = params[\"WEIGHT_LIST\"]\n",
    "    self.longest_n = max(self.n_list)\n",
    "    self.out_vocab = params[\"OUT_VOCAB\"]\n",
    "    \n",
    "  def forward(self, seq): \n",
    "    \n",
    "    seq_len = seq.shape[\"seqlen\"]\n",
    "    batch_size = seq.shape[\"batch\"]\n",
    "      \n",
    "    pad_token = TEXT.vocab.stoi[\"<pad>\"]\n",
    "    additional_padding = ntorch.ones(batch_size, self.longest_n, \n",
    "                                    names=(\"batch\", \"seqlen\")).long()\n",
    "    additional_padding *= pad_token\n",
    "    \n",
    "    seq = ntorch.cat([additional_padding, seq, additional_padding],\n",
    "                    dim=\"seqlen\")\n",
    "    \n",
    "    \n",
    "    amino_acids = self.codon_to_aa[seq.values]\n",
    "    \n",
    "    return_ar = ntorch.zeros(seq_len, batch_size, self.out_vocab,\n",
    "                             names=(\"seqlen\", \"batch\", \"vocablen\"))\n",
    "    \n",
    "    # convert to numpy to leave GPU \n",
    "    amino_acids = amino_acids.detach().cpu().numpy()\n",
    "    for batch_item in range(batch_size): \n",
    "      # start at n, end at seq_len - n\n",
    "      for seq_item in range(self.longest_n, seq_len - self.longest_n):        \n",
    "        # Must iterate over all dictionaries\n",
    "        for weight, n, ngram_dict in zip(self.weight_list, \n",
    "                                         self.n_list, self.dict_list):          \n",
    "          # N gram is a 2d numpy array containing an amino acid embedding in each row\n",
    "          n_gram = amino_acids[batch_item,seq_item - n : seq_item + n + 1]\n",
    "\n",
    "          # note, we want to populate the return ar before padding!\n",
    "          return_ar[{\"seqlen\" : seq_item - self.longest_n, \n",
    "                     \"batch\" : batch_item}] += weight * ngram_dict[str(n_gram)].float()\n",
    "\n",
    "    return return_ar\n",
    "  \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FGKLRU1-mrwj"
   },
   "source": [
    "#### AA_BILSTM\n",
    "A model to compress a codon sequence into its amino acid representation and then run a bidirectional LSTM over this sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ouCELjHjmxHw"
   },
   "outputs": [],
   "source": [
    "class AA_BILSTM(ntorch.nn.Module):\n",
    "  '''\n",
    "  Compress info for codon sequence at the amino acid level\n",
    "  '''\n",
    "  \n",
    "  def __init__(self, params): \n",
    "    super(AA_BILSTM, self).__init__()\n",
    "    self.codon_to_aa = params[\"CODON_TO_AA\"]\n",
    "    self.embedding_size = params[\"EMBED_DIM\"]\n",
    "    self.hiddenlen = params[\"HIDDEN_LEN\"]\n",
    "    self.num_layers = params[\"NUM_LAYERS\"]\n",
    "    self.lstm_dropout = params[\"LSTM_DROPOUT\"]\n",
    "    self.bidirectional = params[\"BIDIRECTIONAL\"]\n",
    "    self.num_directions = 1\n",
    "    if self.bidirectional:\n",
    "      self.num_directions = 2\n",
    "    \n",
    "    self.aa_embed = (ntorch.nn.Embedding.from_pretrained(self.codon_to_aa)\n",
    "                     .spec(\"seqlen\", \"embedlen\"))\n",
    "    \n",
    "    # don't learn these.. \n",
    "    self.aa_embed.weight.requires_grad_(False)  \n",
    "    \n",
    "    self.LSTM = (ntorch.nn.LSTM(self.embedding_size, self.hiddenlen,\n",
    "                                num_layers=self.num_layers, \n",
    "                                bidirectional=self.bidirectional\n",
    "                               )\n",
    "                .spec(\"embedlen\", \"seqlen\", name_out=\"hiddenlen\")\n",
    "                )\n",
    "    \n",
    "    \n",
    "  def forward(self, seq): \n",
    "    '''\n",
    "    Forward pass\n",
    "    ''' \n",
    "    aa_rep = self.aa_embed(seq)    \n",
    "    h_0 = ntorch.zeros(self.num_layers * self.num_directions, aa_rep.shape[\"batch\"], self.hiddenlen, \n",
    "                        names=(\"layers\", \"batch\", \"hiddenlen\")).to(device)\n",
    "    c_0 = ntorch.zeros(self.num_layers * self.num_directions, aa_rep.shape[\"batch\"], self.hiddenlen, \n",
    "                        names=(\"layers\", \"batch\", \"hiddenlen\")).to(device)\n",
    "    \n",
    "    h_0 = h_0.transpose(\"batch\", \"layers\", \"hiddenlen\")\n",
    "    c_0 = c_0.transpose(\"batch\", \"layers\", \"hiddenlen\")\n",
    "    hidden_states, (h_n, c_n) = self.LSTM(aa_rep, (h_0, c_0))\n",
    "    \n",
    "    return hidden_states\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JtfO85lwm5nO"
   },
   "source": [
    "#### Frequency Based Model\n",
    "A unigram model that only uses a single amino acid to do prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-0CQkRjm4ss"
   },
   "outputs": [],
   "source": [
    "class FreqModel(ntorch.nn.Module):\n",
    "  ''' \n",
    "  Simple language model that uses the frequencies of the amino acids for modeling\n",
    "  Magic happens in aa_info model\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super(FreqModel, self).__init__()\n",
    "\n",
    "  def forward(self, text, aa_info):\n",
    "    ''' \n",
    "      Pass in context for the next amino acid\n",
    "    '''\n",
    "\n",
    "    return aa_info.rename(\"hiddenlen\", \"vocablen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i0159i6ynCf-"
   },
   "source": [
    "#### Codon Level Language Model \n",
    "A model that uses the previously predicted (or true) codons in addition to provided information about the amino acid for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dHmsrfdLmxB1"
   },
   "outputs": [],
   "source": [
    "class NNLM(ntorch.nn.Module):\n",
    "  ''' \n",
    "  Simple LSTM class.\n",
    "  '''\n",
    "  def __init__(self, params):\n",
    "    super(NNLM, self).__init__()\n",
    "    self.vocab_size = params[\"VOCAB_SIZE\"]\n",
    "    self.embedding_size = params[\"EMBED_DIM\"]\n",
    "    self.hiddenlen = params[\"HIDDEN_LEN\"]\n",
    "    self.num_layers = params[\"NUM_LAYERS\"]\n",
    "    self.linear_dropout = ntorch.nn.Dropout(p=params[\"LINEAR_DROPOUT\"])\n",
    "    self.lstm_dropout = params[\"LSTM_DROPOUT\"]\n",
    "    self.out_vocab = params[\"OUT_VOCAB\"]\n",
    "    self.aa_info_size = params[\"AA_COMPRESS_SIZE\"]\n",
    "    self.teacher_force_prob = params[\"TEACHER_FORCE\"]\n",
    "    if self.embedding_size is not None: \n",
    "      self.embedding = ntorch.nn.Embedding(num_embeddings=params[\"VOCAB_SIZE\"], \n",
    "                                           embedding_dim = self.embedding_size).spec(\"seqlen\", \"embedlen\")\n",
    "    else: \n",
    "      self.embedding = (ntorch.nn.Embedding.\n",
    "                        from_pretrained(torch.eye(len(TEXT.vocab.itos))\n",
    "                                       )\n",
    "                       ).spec(\"seqlen\", \"embedlen\")\n",
    "      \n",
    "      self.embedding.weight.requires_grad_(False)\n",
    "      self.embedding_size = len(TEXT.vocab.itos)\n",
    "    \n",
    "    self.LSTM = (ntorch.nn.LSTM(self.embedding_size, self.hiddenlen, num_layers=self.num_layers)\n",
    "                .spec(\"embedlen\", \"seqlen\", name_out=\"hiddenlen\")\n",
    "                )\n",
    "    self.linear = (ntorch.nn.Linear(self.hiddenlen + self.aa_info_size, \n",
    "                                    self.out_vocab)\n",
    "                   .spec(\"hiddenlen\", \"vocablen\")\n",
    "                  )\n",
    "    \n",
    "  def set_to_eval(self):\n",
    "    self.dropout.eval()\n",
    "  \n",
    "  def set_teacher_force(self, new_prob):\n",
    "    self.teacher_force_prob = new_prob\n",
    "    \n",
    "  def forward(self, text, aa_info):\n",
    "    ''' \n",
    "      Pass in context for the next amino acid\n",
    "    '''\n",
    "    \n",
    "    # Reset for each new batch...\n",
    "    h_0 = ntorch.zeros(text.shape[\"batch\"], self.num_layers, self.hiddenlen, \n",
    "                        names=(\"batch\", \"layers\", \"hiddenlen\")).to(device)\n",
    "    c_0 = ntorch.zeros(text.shape[\"batch\"], self.num_layers, self.hiddenlen, \n",
    "                        names=(\"batch\", \"layers\", \"hiddenlen\")).to(device)\n",
    " \n",
    "    # If we should use all the sequence as input\n",
    "    if self.teacher_force_prob == 1: \n",
    "      text_embedding = self.embedding(text)\n",
    "      hidden_states, (h_n, c_n) = self.LSTM(text_embedding, (h_0, c_0))\n",
    "      output = self.linear_dropout(hidden_states)\n",
    "      output = ntorch.cat([output, aa_info], dim=\"hiddenlen\")\n",
    "      output = self.linear(output)\n",
    "    \n",
    "    # If we should use some combination of teacher forcing\n",
    "    else: \n",
    "      # Use for teacher forcing...\n",
    "      outputs = []\n",
    "      model_input = text[{\"seqlen\" : slice(0, 1)}]\n",
    "      for position in range(text.shape[\"seqlen\"]): \n",
    "        text_embedding = self.embedding(model_input)\n",
    "        hidden_states, (h_n, c_n) = self.LSTM(text_embedding, (h_0, c_0))\n",
    "\n",
    "        output = self.linear_dropout(hidden_states)\n",
    "        aa_info_subset = aa_info[{\"seqlen\" : slice(position, position+1)}]\n",
    "        output = ntorch.cat([output, aa_info_subset], dim=\"hiddenlen\")\n",
    "\n",
    "        output = self.linear(output)\n",
    "        outputs.append(output)\n",
    "\n",
    "        # Define next input... \n",
    "        if random.random() < self.teacher_force_prob: \n",
    "          model_input = text[{\"seqlen\" : slice(position, position+1)}]\n",
    "        else: \n",
    "          # TODO: Should we be masking this output?\n",
    "          model_input = output.argmax(\"vocablen\")\n",
    "          \n",
    "      output = ntorch.cat(outputs, dim=\"seqlen\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6UDyAMW1nOIa"
   },
   "source": [
    "#### AA_ONLY \n",
    "A model that only uses a bidirectional LSTM over the amino acids in order to do prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kmba1P1CnNs6"
   },
   "outputs": [],
   "source": [
    "class AA_ONLY(ntorch.nn.Module):\n",
    "  ''' \n",
    "  Simple model to predict the output codons using only the input amino acid\n",
    "  '''\n",
    "  def __init__(self, params):\n",
    "    super(AA_ONLY, self).__init__()\n",
    "    self.out_vocab = params[\"OUT_VOCAB\"]\n",
    "    self.aa_info_size = params[\"AA_COMPRESS_SIZE\"]\n",
    "    self.linear = (ntorch.nn.Linear(self.aa_info_size, \n",
    "                                    self.out_vocab)\n",
    "                   .spec(\"hiddenlen\", \"vocablen\")\n",
    "                  )\n",
    "    \n",
    "  def forward(self, text, aa_info):\n",
    "    ''' \n",
    "      Pass in context for the next amino acid\n",
    "    '''\n",
    "\n",
    "    output = aa_info\n",
    "    output = self.linear(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ClG_oqYXmdpI"
   },
   "source": [
    "### Nucleotide Level Models\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sza5q9G2aadG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "noFpLqcOeN9X"
   },
   "source": [
    "## Train, Acc, PPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x--R1qhVcprx"
   },
   "outputs": [],
   "source": [
    "def train_model(train_iter, model, aa_compress, train_params, \n",
    "                optimizer, optimizer_aa=None):\n",
    "  '''\n",
    "  Train a given model \n",
    "  \n",
    "  TODO: \n",
    "  - Mask all non synonymous codons in test only\n",
    "    For now, we can do this at prediction time.. \n",
    "  - Precompute the text / target in the iterator function \n",
    "  \n",
    "  NOTE: \n",
    "    Optimizer_aa is optional if we want to learn on the compressions.\n",
    "  ''' \n",
    "  \n",
    "  model.train()\n",
    "  if \"TEACHER_FORCE\" in train_params:\n",
    "    model.teacher_force_prob = train_params[\"TEACHER_FORCE\"]\n",
    "\n",
    "  if optimizer_aa is not None:\n",
    "    # Does this accidentally turn on gradients? \n",
    "    aa_compress.train()\n",
    "    \n",
    "  loss_function = ntorch.nn.CrossEntropyLoss().spec(\"vocablen\")\n",
    "  model.to(device)\n",
    "  aa_compress.to(device)\n",
    "  loss_values = []\n",
    "  for epoch in range(train_params[\"num_epochs\"]):\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(train_iter):\n",
    "      model.zero_grad()\n",
    "      if optimizer_aa: \n",
    "        aa_compress.zero_grad()\n",
    "\n",
    "      \n",
    "      # Select for all non zero tensors\n",
    "      # Use this to find all indices that aren't padding\n",
    "      seq_len = batch.sequence.shape[\"seqlen\"]\n",
    "      text = batch.sequence.narrow(\"seqlen\", 0, seq_len - 1)\n",
    "      target = batch.sequence.narrow(\"seqlen\", 1, seq_len - 1)\n",
    "      \n",
    "      stacked_target = target.stack(dims=(\"batch\", \"seqlen\"), \n",
    "                                          name=\"seqlen\")\n",
    "\n",
    "      mask = (stacked_target != TEXT.vocab.stoi[\"<pad>\"])\n",
    "      prop_indices = (ntorch.nonzero(mask)\n",
    "                      .get(\"inputdims\", 0)\n",
    "                     )\n",
    "      # Forward\n",
    "      predictions = model(text, aa_compress(target)) \n",
    "      \n",
    "      # Stack the predictions into one long vector\n",
    "      predictions = predictions.stack(dims=(\"batch\", \"seqlen\"), name=\"seqlen\")\n",
    "            \n",
    "      # Only find loss on sequences\n",
    "      # TODO: Divide by batch size... \n",
    "      loss = loss_function(predictions.index_select(\"seqlen\", prop_indices),\n",
    "                           stacked_target.index_select(\"seqlen\", prop_indices))\n",
    "      \n",
    "      epoch_loss += loss.item()\n",
    "      \n",
    "      loss.backward()\n",
    "      # gradient clip\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), train_params[\"grad_clip\"])\n",
    "      optimizer.step()\n",
    "      \n",
    "      if optimizer_aa: \n",
    "        torch.nn.utils.clip_grad_norm_(aa_compress.parameters(), train_params[\"grad_clip\"])\n",
    "        optimizer_aa.step()\n",
    "\n",
    "      \n",
    "\n",
    "    print(\"Epoch: {} -- Loss: {}\".format(epoch, epoch_loss))        \n",
    "    loss_values.append(epoch_loss)\n",
    "\n",
    "  if train_params[\"plot_loss\"]: \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot([t for t in range(len(loss_values))], loss_values)\n",
    "    ax.set(xlabel='Epochs', ylabel='Loss', title='Loss during Optimization')\n",
    "    plt.show()\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dHHHEu5CbHjF"
   },
   "source": [
    "#### Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1qKd_VyCJhIJ"
   },
   "outputs": [],
   "source": [
    "def accuracy(data_iter, model, aa_compress, teacher_force=0):\n",
    "  '''\n",
    "  Produce accuracy (# correct / total)\n",
    "  TODO: \n",
    "  - Mask all non synonymous codons in train\n",
    "    For now, we can do this at prediction time.. \n",
    "  - Precompute the text / target in the iterator function \n",
    "  ''' \n",
    "  \n",
    "  model.to(device)\n",
    "  model.eval()\n",
    "  model.teacher_force_prob = teacher_force\n",
    "  aa_compress.to(device)\n",
    "  aa_compress.eval()\n",
    "  num_correct = 0 \n",
    "  num_total = 0 \n",
    "  with torch.no_grad():\n",
    "    for i, batch in enumerate(data_iter):\n",
    "      \n",
    "      # Select for all non zero tensors\n",
    "      # Use this to find all indices that aren't padding\n",
    "      seq_len = batch.sequence.shape[\"seqlen\"]\n",
    "      text = batch.sequence.narrow(\"seqlen\", 0, seq_len - 1)\n",
    "      target = batch.sequence.narrow(\"seqlen\", 1, seq_len - 1)\n",
    "      \n",
    "      stacked_target = target.stack(dims=(\"batch\", \"seqlen\"), \n",
    "                                          name=\"seqlen\")\n",
    "      mask = (stacked_target != TEXT.vocab.stoi[\"<pad>\"])\n",
    "      prop_indices = (ntorch.nonzero(mask)\n",
    "                      .get(\"inputdims\", 0)\n",
    "                     ).rename(\"elements\", \"seqlen\")\n",
    "      # Forward\n",
    "      predictions = model(text, aa_compress(target)) \n",
    "      # Mask all outputs that don't work\n",
    "      mask_bad_codons = ntorch.tensor(mask_tbl[target.values], \n",
    "                         names=(\"seqlen\", \"batch\", \"vocablen\")).float()\n",
    "      predictions = (mask_bad_codons.double() + predictions.double())\n",
    "\n",
    "     \n",
    "      # Stack the predictions into one long vector\n",
    "    \n",
    "      predictions = predictions.stack(dims=(\"batch\", \"seqlen\"), name=\"seqlen\")\n",
    "\n",
    "      predictions = predictions.argmax(\"vocablen\").index_select(\"seqlen\", \n",
    "                                                                prop_indices)\n",
    "      stacked_target = stacked_target.index_select(\"seqlen\", prop_indices)\n",
    "            \n",
    "      num_correct += (predictions == stacked_target).sum().item()   \n",
    "      num_total += predictions.shape[\"seqlen\"]\n",
    "      \n",
    "      # For quick results, toggle this\n",
    "#       if i == 20: \n",
    "#         break\n",
    "      \n",
    "#   return num_correct / num_total \n",
    "\n",
    "  return (predictions, stacked_target, num_correct / num_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZqmKvOqbDA3"
   },
   "source": [
    "#### PPL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BeX8qB2RYSyY"
   },
   "outputs": [],
   "source": [
    "def PPL(data_iter, model, aa_compress, teacher_force=0):\n",
    "  '''\n",
    "  Produce average ppl of prediction\n",
    "  TODO: \n",
    "  - Mask all non synonymous codons in train\n",
    "    For now, we can do this at prediction time.. \n",
    "  - Precompute the text / target in the iterator function \n",
    "  ''' \n",
    "  \n",
    "  model.to(device)\n",
    "  model.eval()\n",
    "  model.teacher_force_prob = teacher_force\n",
    "  aa_compress.to(device)\n",
    "  aa_compress.eval()\n",
    "  ppl = 0\n",
    "  num_total = 0 \n",
    "  loss_function = ntorch.nn.CrossEntropyLoss(reduction=\"none\").spec(\"vocablen\")\n",
    "  with torch.no_grad():\n",
    "    for i, batch in enumerate(data_iter):\n",
    "      \n",
    "      # Select for all non zero tensors\n",
    "      # Use this to find all indices that aren't padding\n",
    "      seq_len = batch.sequence.shape[\"seqlen\"]\n",
    "      text = batch.sequence.narrow(\"seqlen\", 0, seq_len - 1)\n",
    "      target = batch.sequence.narrow(\"seqlen\", 1, seq_len - 1)\n",
    "      \n",
    "      stacked_target = target.stack(dims=(\"batch\", \"seqlen\"), \n",
    "                                          name=\"seqlen\")\n",
    "      mask = (stacked_target != TEXT.vocab.stoi[\"<pad>\"])\n",
    "      prop_indices = (ntorch.nonzero(mask)\n",
    "                      .get(\"inputdims\", 0)\n",
    "                     ).rename(\"elements\", \"seqlen\")\n",
    "      # Forward\n",
    "      predictions = model(text, aa_compress(target)) \n",
    "      # Mask all outputs that don't work\n",
    "      mask_bad_codons = ntorch.tensor(mask_tbl[target.values], \n",
    "                         names=(\"seqlen\", \"batch\", \"vocablen\")).float()\n",
    "      predictions = (mask_bad_codons.double() + predictions.double())\n",
    "        \n",
    "     \n",
    "      # Stack the predictions into one long vector\n",
    "      predictions = predictions.stack(dims=(\"batch\", \"seqlen\"), name=\"seqlen\")\n",
    "      loss = loss_function(predictions.index_select(\"seqlen\", prop_indices),\n",
    "                     stacked_target.index_select(\"seqlen\", prop_indices))\n",
    "      ppl += loss.exp().sum().item()\n",
    "      num_total += loss.shape[\"seqlen\"]      \n",
    "      # For quick results, toggle this\n",
    "#       if i == 20: \n",
    "#         break\n",
    "\n",
    "  return ppl / num_total "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m8-ZoDTVH8Kf"
   },
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function torchtext.vocab._default_unk_index()>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             'L': 2,\n",
       "             'R': 3,\n",
       "             'S': 4,\n",
       "             'A': 5,\n",
       "             'G': 6,\n",
       "             'P': 7,\n",
       "             'T': 8,\n",
       "             'V': 9,\n",
       "             '*': 10,\n",
       "             'I': 11,\n",
       "             'C': 12,\n",
       "             'D': 13,\n",
       "             'E': 14,\n",
       "             'F': 15,\n",
       "             'H': 16,\n",
       "             'K': 17,\n",
       "             'N': 18,\n",
       "             'Q': 19,\n",
       "             'Y': 20,\n",
       "             'M': 21,\n",
       "             'W': 22})"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AA_LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yNaqhFpMH6oM"
   },
   "outputs": [],
   "source": [
    "def output_predictions_and_target(data_iter, model, aa_compress, teacher_force=0):\n",
    "  '''\n",
    "  Outputs matrix for prediction, target, and also the accuracy\n",
    "  ''' \n",
    "  \n",
    "  \n",
    "  model.to(device)\n",
    "  model.eval()\n",
    "  model.teacher_force_prob = teacher_force\n",
    "  aa_compress.to(device)\n",
    "  aa_compress.eval()\n",
    "  num_correct = 0 \n",
    "  num_total = 0 \n",
    "  \n",
    "  prediction_list = []\n",
    "  target_list = []\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for i, batch in enumerate(data_iter):\n",
    "      \n",
    "      # Select for all non zero tensors\n",
    "      # Use this to find all indices that aren't padding\n",
    "      seq_len = batch.sequence.shape[\"seqlen\"]\n",
    "      text = batch.sequence.narrow(\"seqlen\", 0, seq_len - 1)\n",
    "      target = batch.sequence.narrow(\"seqlen\", 1, seq_len - 1)\n",
    "      \n",
    "      for i in range(target.shape['batch']):\n",
    "            target_list.append(target[{\"batch\": i}])\n",
    "    \n",
    "      stacked_target = target.stack(dims=(\"batch\", \"seqlen\"), \n",
    "                                          name=\"seqlen\")\n",
    "      mask = (stacked_target != TEXT.vocab.stoi[\"<pad>\"])\n",
    "      prop_indices = (ntorch.nonzero(mask)\n",
    "                      .get(\"inputdims\", 0)\n",
    "                     ).rename(\"elements\", \"seqlen\")\n",
    "      # Forward\n",
    "      predictions = model(text, aa_compress(target)) \n",
    "      # Mask all outputs that don't work\n",
    "      mask_bad_codons = ntorch.tensor(mask_tbl[target.values], \n",
    "                         names=(\"seqlen\", \"batch\", \"vocablen\")).float()\n",
    "      predictions = (mask_bad_codons.double() + predictions.double())\n",
    "      \n",
    "      for i in range(predictions.shape['batch']):\n",
    "          prediction = predictions[{\"batch\": i}]\n",
    "#           print (prediction.argmax(\"vocablen\"))\n",
    "          prediction = prediction.argmax(\"vocablen\")\n",
    "          prediction_list.append(prediction.cpu())\n",
    "    \n",
    "    \n",
    "      # Stack the predictions into one long vector\n",
    "      predictions = predictions.stack(dims=(\"batch\", \"seqlen\"), name=\"seqlen\")\n",
    "\n",
    "      predictions = predictions.argmax(\"vocablen\").index_select(\"seqlen\", \n",
    "                                                                prop_indices)\n",
    "      \n",
    "      stacked_target = stacked_target.index_select(\"seqlen\", prop_indices)\n",
    "      \n",
    "            \n",
    "      num_correct += (predictions == stacked_target).sum().item()   \n",
    "      num_total += predictions.shape[\"seqlen\"]\n",
    "\n",
    "  return (prediction_list, target_list, num_correct / num_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.5154762513919245\n"
     ]
    }
   ],
   "source": [
    "test_unigram_predicts, test_target_vals, unigram_test_ac = output_predictions_and_target(test_iter_bucket, model, aa_compress)\n",
    "# train_unigram_predicts, train_target_vals, unigram_train_ac = output_predictions_and_target(test_iter_bucket, model, aa_compress)\n",
    "\n",
    "# unigram_test_ac = accuracy(test_iter_bucket, model, aa_compress)\n",
    "\n",
    "# print(\"Train accuracy: \", unigram_train_ac)\n",
    "print(\"Test accuracy: \", unigram_test_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1316"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_unigram_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E6fn1LDOYGXe"
   },
   "outputs": [],
   "source": [
    "def mismatched_indices(predict_list, target_list):\n",
    "  '''\n",
    "  Inputs prediction and true target, outputs mismatch list and mismatch positions\n",
    "  \n",
    "  mismatch list is a NUM_SEQUENCE x LEN_SEQUENCE list of lists, boolean values. 1 if prediction is correct, 0 if incorrect.\n",
    "  (e.g. [0, 1, 1, 0, 0, ...])\n",
    "  \n",
    "  msimatch positions contains positions in which misclassification happened (e.g. [3, 4, 9, 13, 31])\n",
    "  \n",
    "  '''\n",
    "  mismatch_list = []\n",
    "  for i in range(len(predict_list)):\n",
    "    mismatches = predict_list[i] != target_list[i]\n",
    "    mismatch_list.append(np.array(mismatches.values))\n",
    "  \n",
    "  mismatch_positions = []\n",
    "  for i in range(len(mismatch_list)):\n",
    "    positions = [j for j, x in enumerate(mismatch_list[i]) if x == 1]\n",
    "    mismatch_positions.append(positions)\n",
    "    \n",
    "  return (mismatch_list, mismatch_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xai-jkALZLfh"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import zip_longest\n",
    "\n",
    "def pool_mismatches(mismatch_list, mismatch_indices):\n",
    "  '''\n",
    "  Given mismatch list and mismatch positions, outputs error rate over sequence length\n",
    "  \n",
    "  METHOD: counts error in every position over all the test sequences. Misclassification at each position is counted,\n",
    "  and normalized over how many sequences have a position there. (e.g. all 132 sequences have a nt in position 1, \n",
    "  but only a few would have it at position 9432.)\n",
    "  \n",
    "  \n",
    "  '''\n",
    "  collapsed_array = []\n",
    "  for item in mismatch_indices:\n",
    "    collapsed_array.extend(item)\n",
    "    \n",
    "  \n",
    "  counts = Counter(collapsed_array)\n",
    "  \n",
    "  #normalize the counts\n",
    "  seq_lengths = []\n",
    "  for item in mismatch_list:\n",
    "    seq_lengths.append(len(item))\n",
    "      \n",
    "  normalizing_list = np.array([0] * max(seq_lengths))\n",
    "\n",
    "  for length in seq_lengths:\n",
    "    normalizing_list = [sum(n) for n in zip_longest(normalizing_list, [1]*length, fillvalue=0)]\n",
    "    \n",
    "  for i in range(max(seq_lengths)):\n",
    "    counts[i] = counts[i] / normalizing_list[i]\n",
    "    \n",
    "  normalized_counts = [0]*max(seq_lengths)\n",
    "  \n",
    "  for key in counts:\n",
    "    try:\n",
    "      normalized_counts[key] = counts[key]\n",
    "    except:\n",
    "      print (key)\n",
    "    \n",
    "  return normalized_counts\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8rtOdj3dbEvX"
   },
   "source": [
    "####  Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fwtUEnoFQRb"
   },
   "outputs": [],
   "source": [
    "def get_prediction(batch, model, aa_compress): \n",
    "  ''' Predict outputs from sequence'''\n",
    "  model.to(device)\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    seq_len = batch.sequence.shape[\"seqlen\"]\n",
    "    text = batch.sequence.narrow(\"seqlen\", 0, seq_len - 1)\n",
    "    target = batch.sequence.narrow(\"seqlen\", 1, seq_len - 1)\n",
    "    # Forward\n",
    "    predictions = model(text, aa_compress(target)) \n",
    "    mask_bad_codons = ntorch.tensor(mask_tbl[target.values], \n",
    "                       names=(\"seqlen\", \"batch\", \"vocablen\")).float()\n",
    "    predictions = (mask_bad_codons + predictions)\n",
    "    predictions = predictions.argmax(\"vocablen\")\n",
    "  return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JN8cVZYMxkNw"
   },
   "source": [
    "## Unigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4N3M6r1xwTV"
   },
   "outputs": [],
   "source": [
    "unigram_freq_tbl = make_unigram_conversion(train_iter_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "gTwN6sUwxmpg",
    "outputId": "d2dc7062-2af1-4aee-f937-9a09ccfad74f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FreqModel(), AA_COMPRESS(\n",
       "   (aa_embed): Embedding(67, 67)\n",
       " ))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "aa_compress_params = {\n",
    "    \"CODON_TO_AA\" : unigram_freq_tbl\n",
    "}\n",
    "\n",
    "\n",
    "model = FreqModel()\n",
    "aa_compress = AA_COMPRESS(aa_compress_params)\n",
    "model.to(device), aa_compress.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yaBq11QXxmmh",
    "outputId": "5580f670-8a3e-43c1-d12a-373765486aba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.5154762513919245\n"
     ]
    }
   ],
   "source": [
    "test_unigram_predicts, test_target_vals, unigram_test_ac = output_predictions_and_target(test_iter_bucket, model, aa_compress)\n",
    "# train_unigram_predicts, train_target_vals, unigram_train_ac = output_predictions_and_target(test_iter_bucket, model, aa_compress)\n",
    "\n",
    "# unigram_test_ac = accuracy(test_iter_bucket, model, aa_compress)\n",
    "\n",
    "# print(\"Train accuracy: \", unigram_train_ac)\n",
    "print(\"Test accuracy: \", unigram_test_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "i-5DE_LZXQoF",
    "outputId": "7a587a5b-d6c0-497a-b2a7-0ad5d3a91687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1316"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_target_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VUglocblXVT8"
   },
   "outputs": [],
   "source": [
    "out = mismatched_indices(test_unigram_predicts, test_target_vals)\n",
    "mismatch_over_sequence = pool_mismatches(out[0], out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eG9Z2Yp92888"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = mismatched_indices(test_unigram_predicts, test_target_vals)\n",
    "mismatch_over_sequence = pool_mismatches(out[0], out[1])\n",
    "plt.scatter(range(len(mismatch_over_sequence))[:300], mismatch_over_sequence[:300])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "nzOavnI1xmi0",
    "outputId": "59c5a368-4f8e-43d9-edad-9f85992fdf92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train PPL:  3.379582556636873\n",
      "Test PPL:  3.395484078717863\n"
     ]
    }
   ],
   "source": [
    "test_ppl, train_ppl = (PPL(test_iter_bucket, model, aa_compress), \n",
    "                     PPL(train_iter_bucket, model, aa_compress))\n",
    "print(\"Train PPL: \", train_ppl)\n",
    "print(\"Test PPL: \", test_ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "iu91yG0sxmez",
    "outputId": "72b0a4c2-8bfe-485f-b6b4-594f2f480254"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NamedTensor(\n",
       "\ttensor([10, 28,  8,  ..., 19,  2, 63]),\n",
       "\t('seqlen',))"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_unigram_predicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yf1SN58HXNEn"
   },
   "source": [
    "## N-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnrnYD05XL-d"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-057c353232c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# n_grams are indices in amino acid space, targets are indices in codon space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn_grams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_n_gram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter_bucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodon_to_aa_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mzero_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_grams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_grams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_n_gram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter_bucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodon_to_aa_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-edf90ba7652b>\u001b[0m in \u001b[0;36mmake_n_gram\u001b[0;34m(train_iter, n, amino_acid_conversion)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       seq = ntorch.cat([additional_padding, batch.sequence, additional_padding],\n\u001b[0;32m---> 25\u001b[0;31m                       dim=\"seqlen\")\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0;31m# Now one hots..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/ML_env/lib/python3.6/site-packages/namedtensor/torch_base.py\u001b[0m in \u001b[0;36mcat\u001b[0;34m(tensors, dim)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_names\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# n_grams are indices in amino acid space, targets are indices in codon space\n",
    "n_grams, targets = make_n_gram(train_iter_bucket, 0, codon_to_aa_index)\n",
    "zero_dict = build_dictionary(n_grams, targets)\n",
    "\n",
    "n_grams, targets = make_n_gram(train_iter_bucket, 1, codon_to_aa_index)\n",
    "one_dict = build_dictionary(n_grams, targets)\n",
    "\n",
    "n_grams, targets = make_n_gram(train_iter_bucket, 2, codon_to_aa_index)\n",
    "two_dict = build_dictionary(n_grams, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "lfrDwN2yXhuU",
    "outputId": "d3e971ab-3129-4fa8-8d8f-2aa83e155662"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FreqModel(), AA_NGRAM())"
      ]
     },
     "execution_count": 165,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_params = {\n",
    "    # convert each index to the aa index\n",
    "    \"CODON_TO_AA\" : codon_to_aa_index,\n",
    "    \"N_GRAM_DICTS\" : [zero_dict, one_dict],\n",
    "    \"N_LIST\" : [0, 1],\n",
    "    \"WEIGHT_LIST\" : [0.5, 0.5],\n",
    "    \"OUT_VOCAB\" : len(TEXT.vocab.stoi)   \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = FreqModel()\n",
    "aa_compress = AA_NGRAM(aa_params)\n",
    "model.to(device), aa_compress.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "b8w3cVLIXhnR",
    "outputId": "0e2d6fd9-c8d1-4f3f-9ee4-e7e2d0491422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.5508248362762165\n",
      "Test accuracy:  0.48140406958873794\n"
     ]
    }
   ],
   "source": [
    "# train ac should be higher.. something probably wrong.\n",
    "test_ac, train_ac = (accuracy(test_iter_bucket, model, aa_compress),\n",
    "                     accuracy(train_iter_bucket, model, aa_compress))\n",
    "print(\"Train accuracy: \", train_ac)\n",
    "print(\"Test accuracy: \", test_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "I5buwbyHUZmw",
    "outputId": "61b34400-09c6-4354-8f21-e0cfa4588e04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FreqModel(), AA_NGRAM())"
      ]
     },
     "execution_count": 171,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_params = {\n",
    "    # convert each index to the aa index\n",
    "    \"CODON_TO_AA\" : codon_to_aa_index,\n",
    "    \"N_GRAM_DICTS\" : [two_dict],# [zero_dict, one_dict],\n",
    "    \"N_LIST\" : [2],\n",
    "    \"WEIGHT_LIST\" : [1],\n",
    "    \"OUT_VOCAB\" : len(TEXT.vocab.stoi)   \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = FreqModel()\n",
    "aa_compress = AA_NGRAM(aa_params)\n",
    "model.to(device), aa_compress.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kw_D5fYBUZgU"
   },
   "outputs": [],
   "source": [
    "# train ac should be higher.. something probably wrong.\n",
    "test_ac, train_ac = (accuracy(test_iter_bucket, model, aa_compress),\n",
    "                     accuracy(train_iter_bucket, model, aa_compress))\n",
    "print(\"Train accuracy: \", train_ac)\n",
    "print(\"Test accuracy: \", test_ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "umHh-qplxi6N"
   },
   "source": [
    "## Language Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w511Nsl6xiZw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "4FP9Yq5ic7HV",
    "outputId": "2f4119be-e1a3-437c-f974-502ed8aaf653"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(NNLM(\n",
       "   (linear_dropout): Dropout(p=0.2)\n",
       "   (embedding): Embedding(67, 67)\n",
       "   (LSTM): LSTM(67, 200, num_layers=3, batch_first=True)\n",
       "   (linear): Linear(in_features=223, out_features=67, bias=True)\n",
       " ), AA_COMPRESS(\n",
       "   (aa_embed): Embedding(67, 23)\n",
       " ))"
      ]
     },
     "execution_count": 132,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = {\n",
    "    \"VOCAB_SIZE\" : len(TEXT.vocab),\n",
    "    \"EMBED_DIM\" : None, #50,\n",
    "    \"OUT_VOCAB\": len(TEXT.vocab),\n",
    "    \"HIDDEN_LEN\" : 200,\n",
    "    \"NUM_LAYERS\" : 3,\n",
    "    \"LINEAR_DROPOUT\" : 0.2,\n",
    "    \"LSTM_DROPOUT\" : 0.2,    \n",
    "    \"AA_COMPRESS_SIZE\" : index_table.shape[1],\n",
    "    \"TEACHER_FORCE\" : 1\n",
    "}\n",
    "\n",
    "aa_compress_params = {\n",
    "    \"CODON_TO_AA\" : index_table\n",
    "}\n",
    "\n",
    "\n",
    "train_params = {\n",
    "    \"num_epochs\":30, \n",
    "    \"lr\":1e-3,  \n",
    "    \"weight_decay\":1e-6,\n",
    "    \"device\":device, \n",
    "    \"grad_clip\": 10, \n",
    "    \"plot_loss\" : True,\n",
    "    \"TEACHER_FORCE\" : 1\n",
    "}\n",
    "\n",
    "\n",
    "model = NNLM(model_params)\n",
    "aa_compress = AA_COMPRESS(aa_compress_params)\n",
    "model.to(device), aa_compress.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "colab_type": "code",
    "id": "D9PqYDIoem7K",
    "outputId": "15fe8904-2337-4764-f839-0606d5f1ed8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 -- Loss: 1131.959959745407\n",
      "Epoch: 1 -- Loss: 956.8145925998688\n",
      "Epoch: 2 -- Loss: 804.2731750011444\n",
      "Epoch: 3 -- Loss: 680.7200589179993\n",
      "Epoch: 4 -- Loss: 581.9270281791687\n",
      "Epoch: 5 -- Loss: 507.74945878982544\n",
      "Epoch: 6 -- Loss: 454.8769830465317\n",
      "Epoch: 7 -- Loss: 417.3328025341034\n",
      "Epoch: 8 -- Loss: 389.7979357242584\n",
      "Epoch: 9 -- Loss: 370.1917984485626\n",
      "Epoch: 10 -- Loss: 355.9717655181885\n",
      "Epoch: 11 -- Loss: 344.83047610521317\n",
      "Epoch: 12 -- Loss: 336.1347362399101\n",
      "Epoch: 13 -- Loss: 329.4694827198982\n",
      "Epoch: 14 -- Loss: 323.8495211005211\n",
      "Epoch: 15 -- Loss: 319.3141167163849\n",
      "Epoch: 16 -- Loss: 315.29802906513214\n",
      "Epoch: 17 -- Loss: 311.65382105112076\n",
      "Epoch: 18 -- Loss: 307.7892631292343\n",
      "Epoch: 19 -- Loss: 304.555812060833\n",
      "Epoch: 20 -- Loss: 301.6094952225685\n",
      "Epoch: 21 -- Loss: 297.9011378288269\n",
      "Epoch: 22 -- Loss: 294.08951783180237\n",
      "Epoch: 23 -- Loss: 290.21923410892487\n",
      "Epoch: 24 -- Loss: 287.0164201259613\n",
      "Epoch: 25 -- Loss: 283.3129064440727\n",
      "Epoch: 26 -- Loss: 279.5372940301895\n",
      "Epoch: 27 -- Loss: 275.4896043539047\n",
      "Epoch: 28 -- Loss: 272.1893350481987\n",
      "Epoch: 29 -- Loss: 268.1464375257492\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "NNLM(\n",
       "  (linear_dropout): Dropout(p=0.2)\n",
       "  (embedding): Embedding(67, 67)\n",
       "  (LSTM): LSTM(67, 200, num_layers=3, batch_first=True)\n",
       "  (linear): Linear(in_features=223, out_features=67, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=train_params[\"lr\"], weight_decay=train_params[\"weight_decay\"])\n",
    "train_model(train_iter_bucket, model, aa_compress, train_params, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "8LazIWmRgSaw",
    "outputId": "007f674c-4f9b-40f0-d301-878dec4168fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  (NamedTensor(\n",
      "\ttensor([10,  3, 36,  ...,  3, 57, 63], device='cuda:0'),\n",
      "\t('seqlen',)), NamedTensor(\n",
      "\ttensor([10,  3, 43,  ..., 24, 54, 65], device='cuda:0'),\n",
      "\t('seqlen',)), 0.4573393145671263)\n",
      "Test accuracy:  (NamedTensor(\n",
      "\ttensor([10,  7, 16,  ..., 18, 15, 63], device='cuda:0'),\n",
      "\t('seqlen',)), NamedTensor(\n",
      "\ttensor([10,  7, 44,  ..., 62, 15, 63], device='cuda:0'),\n",
      "\t('seqlen',)), 0.45734250204643406)\n"
     ]
    }
   ],
   "source": [
    "test_ac, train_ac = (accuracy(test_iter_bucket, model, aa_compress, teacher_force=0), \n",
    "                     accuracy(train_iter_bucket, model, aa_compress, teacher_force=0))\n",
    "print(\"Train accuracy: \", train_ac)\n",
    "print(\"Test accuracy: \", test_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9fSqJ8Sa6qf"
   },
   "outputs": [],
   "source": [
    "test_ppl, train_ppl = (PPL(test_iter_bucket, model, aa_compress, teacher_force=0), \n",
    "                     PPL(train_iter_bucket, model, aa_compress, teacher_force=0))\n",
    "print(\"Train PPL: \", train_ppl)\n",
    "print(\"Test PPL: \", test_ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "id": "KKbLsivZKEj9",
    "outputId": "213aaaed-4e27-49fc-a61a-6a02ef1e77dd"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-135-746554c4f2e2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    test_ac = (accuracy(test_iter_bucket, model, aa_compress, teacher_force=0)\u001b[0m\n\u001b[0m                                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "test_ac = (accuracy(test_iter_bucket, model, aa_compress, teacher_force=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxQUBDakKHqY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r0qiLM8P-FZ6"
   },
   "source": [
    "## BiLSTM AA Level Only\n",
    "\n",
    "Use only the Amino acids, not the true or predicted codons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rU5U5zDk-JlU"
   },
   "outputs": [],
   "source": [
    "\n",
    "aa_compress_params = {\n",
    "    \"CODON_TO_AA\" : index_table,\n",
    "    \"EMBED_DIM\" : index_table.shape[1],\n",
    "    \"HIDDEN_LEN\" : 50, \n",
    "    \"NUM_LAYERS\" : 3, \n",
    "    \"LSTM_DROPOUT\" : 0.1,\n",
    "    \"BIDIRECTIONAL\" : True\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "model_params = {\n",
    "    \"OUT_VOCAB\": len(TEXT.vocab),\n",
    "    \"AA_COMPRESS_SIZE\" : (aa_compress_params[\"HIDDEN_LEN\"] * \n",
    "                          (2 if aa_compress_params[\"BIDIRECTIONAL\"] else 1))\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "train_params = {\n",
    "    \"num_epochs\":20, \n",
    "    \"lr\":1e-3,  \n",
    "    \"weight_decay\":1e-6,\n",
    "    \"device\":device, \n",
    "    \"grad_clip\": 10, \n",
    "    \"plot_loss\" : True\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = AA_ONLY(model_params)\n",
    "aa_compress = AA_BILSTM(aa_compress_params)\n",
    "model.to(device), aa_compress.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9F_dTGAq-lG4"
   },
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=train_params[\"lr\"],\n",
    "                             weight_decay=train_params[\"weight_decay\"])\n",
    "optimizer_aa = torch.optim.Adam(aa_compress.parameters(), \n",
    "                                lr=train_params[\"lr\"], \n",
    "                                weight_decay=train_params[\"weight_decay\"])\n",
    "\n",
    "\n",
    "train_model(train_iter_bucket, model, aa_compress, train_params,\n",
    "            optimizer, optimizer_aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WRyZhZK-lBy"
   },
   "outputs": [],
   "source": [
    "test_ac, train_ac = (accuracy(test_iter_bucket, model, aa_compress), \n",
    "                     accuracy(train_iter_bucket, model, aa_compress))\n",
    "print(\"Train accuracy: \", train_ac)\n",
    "print(\"Test accuracy: \", test_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZf_-wXI-Jch"
   },
   "outputs": [],
   "source": [
    "test_ppl, train_ppl = (PPL(test_iter_bucket, model, aa_compress), \n",
    "                       PPL(train_iter_bucket, model, aa_compress))\n",
    "print(\"Train PPL: \", train_ppl)\n",
    "print(\"Test PPL: \", test_ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WLFSDti8_E3J"
   },
   "outputs": [],
   "source": [
    "print (AA_BILSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dD9FDxHXO0Kg"
   },
   "source": [
    "## RNN + BiLSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "g04As1G7O2k-",
    "outputId": "785354cd-7d5d-4d19-8b75-0b8300b56f1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(NNLM(\n",
       "   (linear_dropout): Dropout(p=0.2)\n",
       "   (embedding): Embedding(67, 67)\n",
       "   (LSTM): LSTM(67, 100, num_layers=2, batch_first=True)\n",
       "   (linear): Linear(in_features=200, out_features=67, bias=True)\n",
       " ), AA_BILSTM(\n",
       "   (aa_embed): Embedding(67, 23)\n",
       "   (LSTM): LSTM(23, 50, num_layers=3, batch_first=True, bidirectional=True)\n",
       " ))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "aa_compress_params = {\n",
    "    \"CODON_TO_AA\" : index_table,\n",
    "    \"EMBED_DIM\" : index_table.shape[1],\n",
    "    \"HIDDEN_LEN\" : 50, \n",
    "    \"NUM_LAYERS\" : 3, \n",
    "    \"LSTM_DROPOUT\" : 0.1,\n",
    "    \"BIDIRECTIONAL\" : True\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "model_params = {\n",
    "    \"VOCAB_SIZE\" : len(TEXT.vocab),\n",
    "    \"EMBED_DIM\" : None, #50,\n",
    "    \"OUT_VOCAB\": len(TEXT.vocab),\n",
    "    \"HIDDEN_LEN\" : 100,\n",
    "    \"NUM_LAYERS\" : 2,\n",
    "    \"LINEAR_DROPOUT\" : 0.2,\n",
    "    \"LSTM_DROPOUT\" : 0.2,    \n",
    "    \"AA_COMPRESS_SIZE\" : (aa_compress_params[\"HIDDEN_LEN\"] * \n",
    "                          (2 if aa_compress_params[\"BIDIRECTIONAL\"] else 1)),\n",
    "    \"TEACHER_FORCE\" : 1\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "train_params = {\n",
    "    \"num_epochs\":30, \n",
    "    \"lr\":1e-3,  \n",
    "    \"weight_decay\":1e-6,\n",
    "    \"device\":device, \n",
    "    \"grad_clip\": 20, \n",
    "    \"plot_loss\" : True,\n",
    "    \"teacher_force\" : 1\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = NNLM(model_params)\n",
    "aa_compress = AA_BILSTM(aa_compress_params)\n",
    "model.to(device), aa_compress.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "colab_type": "code",
    "id": "7nwzRfSVO2Sl",
    "outputId": "d7381190-ffcc-4da0-b135-53a8fbec52ce"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-e9d6be3d7375>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m train_model(train_iter_bucket, model, aa_compress, train_params,\n\u001b[0;32m----> 8\u001b[0;31m             optimizer, optimizer_aa)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-fd58cdcdd8db>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_iter, model, aa_compress, train_params, optimizer, optimizer_aa)\u001b[0m\n\u001b[1;32m     59\u001b[0m       \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m       \u001b[0;31m# gradient clip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"grad_clip\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/ML_env/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/ML_env/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=train_params[\"lr\"],\n",
    "                             weight_decay=train_params[\"weight_decay\"])\n",
    "optimizer_aa = torch.optim.Adam(aa_compress.parameters(), \n",
    "                                lr=train_params[\"lr\"], \n",
    "                                weight_decay=train_params[\"weight_decay\"])\n",
    "\n",
    "train_model(train_iter_bucket, model, aa_compress, train_params,\n",
    "            optimizer, optimizer_aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "colab_type": "code",
    "id": "EXPKdzxyZdIn",
    "outputId": "ee9acd42-6fe1-468d-a15e-0e3858d510ab"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-8f6103fa19a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m test_ac, train_ac = (accuracy(test_iter_bucket, model, aa_compress, teacher_force=1), \n\u001b[0m\u001b[1;32m      2\u001b[0m                      accuracy(train_iter_bucket, model, aa_compress, teacher_force=1))\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "test_ac, train_ac = (accuracy(test_iter_bucket, model, aa_compress, teacher_force=1), \n",
    "                     accuracy(train_iter_bucket, model, aa_compress, teacher_force=1))\n",
    "print(\"Train accuracy: \", train_ac)\n",
    "print(\"Test accuracy: \", test_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "qIJAsVueeMS2",
    "outputId": "17b06c02-f6bb-4479-aefa-a8e91a84b768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train PPL:  3.545165146657026\n",
      "Test PPL:  3.8990431628178577\n"
     ]
    }
   ],
   "source": [
    "test_ppl, train_ppl = (PPL(test_iter_bucket, model, aa_compress, teacher_force=1), \n",
    "                     PPL(train_iter_bucket, model, aa_compress, teacher_force=1))\n",
    "print(\"Train PPL: \", train_ppl)\n",
    "print(\"Test PPL: \", test_ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pvZ8ml3B3FLH"
   },
   "outputs": [],
   "source": [
    "test_lstm_predicts, test_target_vals, lstm_test_ac = output_predictions_and_target(test_iter_bucket, model, aa_compress, teacher_force = 0)\n",
    "# train_unigram_predicts, train_target_vals, unigram_train_ac = prediction_mismatches(test_iter_bucket, model, aa_compress)\n",
    "\n",
    "# unigram_test_ac = accuracy(test_iter_bucket, model, aa_compress)\n",
    "\n",
    "# print(\"Train accuracy: \", unigram_train_ac)\n",
    "# print(\"Test accuracy: \", test_lstm_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rZ1_3mpXkYQ-",
    "outputId": "d439f229-1b91-4c69-b894-91ef33a95c1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.552258961673331"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_test_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Pxb6nz5jOpn"
   },
   "outputs": [],
   "source": [
    "def convert_output_to_DNA(predicts):\n",
    "  seqs = []\n",
    "  \n",
    "  for pred in predicts:\n",
    "    seq = []\n",
    "    for j in range(len(pred)):\n",
    "      seq.append(TEXT.vocab.itos[np.array(pred.values)[j]])\n",
    "    \n",
    "    dna_seq = \"\".join(seq).upper()\n",
    "    seqs.append(dna_seq)\n",
    "    \n",
    "  return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1y718HoFqUzB"
   },
   "outputs": [],
   "source": [
    "output_seqs = convert_output_to_DNA(test_lstm_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9muwRApqYMT"
   },
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqUtils import CodonUsage\n",
    "from Bio.SeqUtils import IUPACData\n",
    "\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "30TixYcprCWn"
   },
   "outputs": [],
   "source": [
    "def count_codons(DNA_seq):\n",
    "  ''' Calculate the counts of each codon given a CDS\n",
    "  \n",
    "  Args:\n",
    "    dna sequence in indexable form\n",
    "    \n",
    "  Returns:\n",
    "    dict{str, int}: dictionary with codons as key and corresponding number of occurences\n",
    "  \n",
    "  '''\n",
    "  \n",
    "  codons_dict = CodonUsage.CodonsDict.copy()\n",
    "  for codon_start in range(0, len(DNA_seq), 3):\n",
    "    codons_dict[str(DNA_seq[codon_start:codon_start+3])] += 1\n",
    "   \n",
    "  return codons_dict\n",
    "\n",
    "\n",
    "def count_codons_fasta(fasta_file):\n",
    "  ''' Calculate the counts of each codon given a set of CDS\n",
    "  \n",
    "  Args:\n",
    "    Fasta file \n",
    "    \n",
    "  Returns:\n",
    "    dict{str, int}: dictionary with codons as key and corresponding number of occurences\n",
    "  \n",
    "  '''\n",
    "  \n",
    "  codons_dict = CodonUsage.CodonsDict.copy()\n",
    "  \n",
    "  for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    seq = record.seq\n",
    "    if len(seq) % 3 != 0:\n",
    "      continue\n",
    "      \n",
    "    #count the codons for this sequence\n",
    "    for codon_start in range(0, len(seq), 3):\n",
    "      codons_dict[str(seq[codon_start:codon_start+3])] += 1\n",
    "   \n",
    "  return codons_dict\n",
    "\n",
    "def count_codons_list(seqs):\n",
    "  ''' Calculate the counts of each codon given list of seqs\n",
    "  \n",
    "  Args:\n",
    "    Fasta file \n",
    "    \n",
    "  Returns:\n",
    "    dict{str, int}: dictionary with codons as key and corresponding number of occurences\n",
    "  \n",
    "  '''\n",
    "  \n",
    "  codons_dict = CodonUsage.CodonsDict.copy()\n",
    "  \n",
    "  for seq in seqs:\n",
    "    if len(seq) % 3 != 0:\n",
    "      continue\n",
    "      \n",
    "    #count the codons for this sequence\n",
    "    for codon_start in range(0, len(seq), 3):\n",
    "      codons_dict[str(seq[codon_start:codon_start+3])] += 1\n",
    "   \n",
    "  return codons_dict\n",
    "\n",
    "def calculate_codon_frequency(codon_counts):\n",
    "  ''' Calculate the counts of each codon given a set of CDS\n",
    "  \n",
    "  Args:\n",
    "    codon usage table\n",
    "    \n",
    "  Returns:\n",
    "    dict{str, float}: dictionary with codons as key and corresponding \n",
    "    frequency of codon for AA\n",
    "  \n",
    "  '''\n",
    "  codon_freqs = CodonUsage.CodonsDict.copy()\n",
    "  \n",
    "  for _, synonymous_codons in CodonUsage.SynonymousCodons.items():\n",
    "    total_AA_count = sum([codon_counts[codon] for codon in synonymous_codons])\n",
    "    \n",
    "    if total_AA_count == 0:\n",
    "      continue\n",
    "      \n",
    "    for codon in synonymous_codons:\n",
    "      codon_freqs[codon] = codon_counts[codon] / total_AA_count\n",
    "  \n",
    "  return codon_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "140bC_2grJON"
   },
   "outputs": [],
   "source": [
    "lstm_codon_table = count_codons_list(output_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dcYYUaBg7atW",
    "outputId": "cbb2ceea-a81e-4ae2-e62a-a21a35689708"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387259"
      ]
     },
     "execution_count": 115,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([lstm_codon_table[key] for key in lstm_codon_table])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1105
    },
    "colab_type": "code",
    "id": "OlCzxMVqsnGJ",
    "outputId": "bb004e2a-1584-41eb-f147-8c1c37e8ab15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAA': 0.9963053487182402,\n",
       " 'AAC': 0.6207480776749642,\n",
       " 'AAG': 0.003694651281759791,\n",
       " 'AAT': 0.37925192232503585,\n",
       " 'ACA': 0.0,\n",
       " 'ACC': 0.764034253092293,\n",
       " 'ACG': 0.23372978116079923,\n",
       " 'ACT': 0.002235965746907707,\n",
       " 'AGA': 0.00022966331358228838,\n",
       " 'AGC': 0.7082299690995343,\n",
       " 'AGG': 4.593266271645767e-05,\n",
       " 'AGT': 0.004439221830526178,\n",
       " 'ATA': 8.149295085975064e-05,\n",
       " 'ATC': 0.2722679488224269,\n",
       " 'ATG': 1.0,\n",
       " 'ATT': 0.7276505582267134,\n",
       " 'CAA': 0.27123995407577495,\n",
       " 'CAC': 0.2496993549797748,\n",
       " 'CAG': 0.728760045924225,\n",
       " 'CAT': 0.7503006450202252,\n",
       " 'CCA': 0.028163358953768498,\n",
       " 'CCC': 0.01238958357232993,\n",
       " 'CCG': 0.8962372375817368,\n",
       " 'CCT': 0.06320981989216473,\n",
       " 'CGA': 0.0,\n",
       " 'CGC': 0.595241376142575,\n",
       " 'CGG': 0.02388498461255799,\n",
       " 'CGT': 0.3805980432685683,\n",
       " 'CTA': 0.0,\n",
       " 'CTC': 0.06438978901969926,\n",
       " 'CTG': 0.9013404825737266,\n",
       " 'CTT': 0.01997901853362863,\n",
       " 'GAA': 0.8579420315390714,\n",
       " 'GAC': 0.14609145643628402,\n",
       " 'GAG': 0.14205796846092855,\n",
       " 'GAT': 0.8539085435637159,\n",
       " 'GCA': 0.07225940089228808,\n",
       " 'GCC': 0.28630231570002124,\n",
       " 'GCG': 0.6170331421287444,\n",
       " 'GCT': 0.02440514127894625,\n",
       " 'GGA': 0.016008537886873,\n",
       " 'GGC': 0.48724481013529797,\n",
       " 'GGG': 0.11323028195682859,\n",
       " 'GGT': 0.3835163700210005,\n",
       " 'GTA': 0.00819093348397119,\n",
       " 'GTC': 0.1454596808360401,\n",
       " 'GTG': 0.6436943934472532,\n",
       " 'GTT': 0.20265499223273548,\n",
       " 'TAA': 0.9485238455715367,\n",
       " 'TAC': 0.6196668744989757,\n",
       " 'TAG': 0.0,\n",
       " 'TAT': 0.3803331255010243,\n",
       " 'TCA': 0.012099055577316447,\n",
       " 'TCC': 0.06593550071810941,\n",
       " 'TCG': 0.15019367193280236,\n",
       " 'TCT': 0.05910258084171128,\n",
       " 'TGA': 0.05147615442846329,\n",
       " 'TGC': 0.7966386554621848,\n",
       " 'TGG': 1.0,\n",
       " 'TGT': 0.20336134453781513,\n",
       " 'TTA': 0.00300734351322998,\n",
       " 'TTC': 0.2974137931034483,\n",
       " 'TTG': 0.011283366359715585,\n",
       " 'TTT': 0.7025862068965517}"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_codon_frequency(lstm_codon_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "u7ZyaPxQq695",
    "outputId": "424b2ac1-d919-4def-d06c-40da595374f7"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-e3c8840d83e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtarget_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_output_to_DNA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_target_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'convert_output_to_DNA' is not defined"
     ]
    }
   ],
   "source": [
    "target_seqs = convert_output_to_DNA(test_target_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4RtL3VZq7HQ"
   },
   "outputs": [],
   "source": [
    "target_codon_table = count_codons_list(target_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1105
    },
    "colab_type": "code",
    "id": "if3BFQvTtIvo",
    "outputId": "4e245094-0b47-4ef9-d449-0ef4f81f92e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAA': 0.7706474165861422,\n",
       " 'AAC': 0.5516095399452626,\n",
       " 'AAG': 0.22935258341385778,\n",
       " 'AAT': 0.44839046005473737,\n",
       " 'ACA': 0.1317316841103711,\n",
       " 'ACC': 0.4326831588962892,\n",
       " 'ACG': 0.26622264509990484,\n",
       " 'ACT': 0.16936251189343482,\n",
       " 'AGA': 0.04000734922603463,\n",
       " 'AGC': 0.2738390564477521,\n",
       " 'AGG': 0.020210371595241375,\n",
       " 'AGT': 0.15162989076032554,\n",
       " 'ATA': 0.0764403879064461,\n",
       " 'ATC': 0.4155325564338685,\n",
       " 'ATG': 1.0,\n",
       " 'ATT': 0.5080270556596854,\n",
       " 'CAA': 0.344833524684271,\n",
       " 'CAC': 0.4261506504864983,\n",
       " 'CAG': 0.655166475315729,\n",
       " 'CAT': 0.5738493495135017,\n",
       " 'CCA': 0.19215326373752437,\n",
       " 'CCC': 0.12395319490650453,\n",
       " 'CCG': 0.5248938855110703,\n",
       " 'CCT': 0.15899965584490078,\n",
       " 'CGA': 0.06651049561343071,\n",
       " 'CGC': 0.3980524551008222,\n",
       " 'CGG': 0.09696385099444214,\n",
       " 'CGT': 0.3782554774700289,\n",
       " 'CTA': 0.03527217624431752,\n",
       " 'CTC': 0.10404476046159226,\n",
       " 'CTG': 0.49609511598088357,\n",
       " 'CTT': 0.10257605781559623,\n",
       " 'GAA': 0.6876046163333627,\n",
       " 'GAC': 0.3674677812608847,\n",
       " 'GAG': 0.3123953836666373,\n",
       " 'GAT': 0.6325322187391152,\n",
       " 'GCA': 0.21282132993414063,\n",
       " 'GCC': 0.270501380922031,\n",
       " 'GCG': 0.35256001699596345,\n",
       " 'GCT': 0.1641172721478649,\n",
       " 'GGA': 0.10865149585155094,\n",
       " 'GGC': 0.40255448066926014,\n",
       " 'GGG': 0.15068681791579164,\n",
       " 'GGT': 0.33810720556339724,\n",
       " 'GTA': 0.15651037988984606,\n",
       " 'GTC': 0.21416466600762604,\n",
       " 'GTG': 0.3677093630843101,\n",
       " 'GTT': 0.26161559101821774,\n",
       " 'TAA': 0.6351249053747161,\n",
       " 'TAC': 0.42950031174846354,\n",
       " 'TAG': 0.07418622255866768,\n",
       " 'TAT': 0.5704996882515365,\n",
       " 'TCA': 0.12373242808025417,\n",
       " 'TCC': 0.1488009748879314,\n",
       " 'TCG': 0.15363189276232755,\n",
       " 'TCT': 0.14836575706140923,\n",
       " 'TGA': 0.2906888720666162,\n",
       " 'TGC': 0.553781512605042,\n",
       " 'TGG': 1.0,\n",
       " 'TGT': 0.446218487394958,\n",
       " 'TTA': 0.1305979717915841,\n",
       " 'TTC': 0.43268255578093306,\n",
       " 'TTG': 0.13141391770602634,\n",
       " 'TTT': 0.5673174442190669}"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_codon_frequency(target_codon_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sD9bhwKnq7BV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IWbAKkUbq7EL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "WBNaUy8u3NI9",
    "outputId": "4eb017c8-815a-40db-9609-0e02d383b14c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = mismatched_indices(test_lstm_predicts, test_target_vals)\n",
    "mismatch_over_sequence = pool_mismatches(out[0], out[1])\n",
    "plt.scatter(range(len(mismatch_over_sequence))[:300], mismatch_over_sequence[:300])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7z9yxiwXOxwp"
   },
   "source": [
    "## Model inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J6MmepHwgStM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3JuDtYVygSwP"
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "batch = next(iter(train_iter_bucket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBzEPjeze1Z4"
   },
   "outputs": [],
   "source": [
    "seqlen = batch.sequence.shape['seqlen']\n",
    "src = batch.sequence.narrow('seqlen',0,seqlen-1)\n",
    "trg = batch.sequence.narrow('seqlen', 1,seqlen-1)\n",
    "aa_compress(trg)\n",
    "model(src, aa_compress(trg)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fPtcnIg38QO"
   },
   "outputs": [],
   "source": [
    "output = model(src, aa_compress(trg))\n",
    "mask_vec = ntorch.tensor(mask_tbl[trg.values], \n",
    "                         names=(\"seqlen\", \"batch\", \"vocablen\")).float()\n",
    "output = (mask_vec + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwUo499Z_2PU"
   },
   "outputs": [],
   "source": [
    "preds = get_prediction(batch, model, aa_compress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TuPTOeAmIGM4"
   },
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRL7mrsaIqTx"
   },
   "outputs": [],
   "source": [
    "def translate_to_seq(x): \n",
    "  ''' Takes in single tensor of name seqlen'''\n",
    "  my_str = \"\".join([TEXT.vocab.itos[i] for i in x.values])\n",
    "  my_str = my_str.split(\"<pad>\")[0]\n",
    "  my_str = my_str.split(\"<unk>\")[0]\n",
    "\n",
    "  if \"<start>\" in my_str: \n",
    "    my_str = my_str.split(\"<start>\")[1]\n",
    "    \n",
    "    \n",
    "  \n",
    "  return my_str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvrZXdREIGRS"
   },
   "outputs": [],
   "source": [
    "src_str = translate_to_seq(batch.sequence.get(\"batch\", 0))\n",
    "res_str = translate_to_seq(preds.get(\"batch\", 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jOwvHkXsIpNx"
   },
   "outputs": [],
   "source": [
    "Seq(src_str).translate(), Seq(res_str).translate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6fTE8PQsLjJX"
   },
   "outputs": [],
   "source": [
    "src_str_tok = np.array(tokenize(src_str))\n",
    "res_str_tok = np.array(tokenize(res_str))\n",
    "correct_locs =  (res_str_tok == src_str_tok)\n",
    "(np.array([str(Seq(i).translate()) for i in src_str_tok[~correct_locs]]),\n",
    "src_str_tok[~correct_locs], res_str_tok[~correct_locs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F0X3n6Q_Un5x"
   },
   "outputs": [],
   "source": [
    "## See relative frequencies of what we predict vs. what's actually used \n",
    "conv_to_prob = lambda x : np.array([eColi_codon_table[y] for y in x])\n",
    "print(\"Source frequencies of mispredicted codons:\\n\", \n",
    "      conv_to_prob(src_str_tok[~correct_locs]) )\n",
    "print(\"Native frequency of mispredicted codons:\\n\", \n",
    "      conv_to_prob(res_str_tok[~correct_locs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oitcGobbn2l5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7z4m1xTbCPZp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QKgVRU41CP2a"
   },
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OfNhgqcfCRIN"
   },
   "outputs": [],
   "source": [
    "def prediction_mismatches(data_iter, model, aa_compress, teacher_force=0):\n",
    "  '''\n",
    "  Produce a NUM_SEQUENCE x LEN_SEQUENCE matrix, boolean values. 1 if prediction is correct, 0 if incorrect\n",
    "  TODO: \n",
    "  - Mask all non synonymous codons in train\n",
    "    For now, we can do this at prediction time.. \n",
    "  - Precompute the text / target in the iterator function \n",
    "  ''' \n",
    "  \n",
    "  model.to(device)\n",
    "  model.eval()\n",
    "  model.teacher_force_prob = teacher_force\n",
    "  aa_compress.to(device)\n",
    "  aa_compress.eval()\n",
    "  num_correct = 0 \n",
    "  num_total = 0 \n",
    "  \n",
    "  prediction_list = []\n",
    "  target_list = []\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for i, batch in enumerate(data_iter):\n",
    "      \n",
    "      # Select for all non zero tensors\n",
    "      # Use this to find all indices that aren't padding\n",
    "      seq_len = batch.sequence.shape[\"seqlen\"]\n",
    "      text = batch.sequence.narrow(\"seqlen\", 0, seq_len - 1)\n",
    "      target = batch.sequence.narrow(\"seqlen\", 1, seq_len - 1)\n",
    "      \n",
    "      stacked_target = target.stack(dims=(\"batch\", \"seqlen\"), \n",
    "                                          name=\"seqlen\")\n",
    "      mask = (stacked_target != TEXT.vocab.stoi[\"<pad>\"])\n",
    "      prop_indices = (ntorch.nonzero(mask)\n",
    "                      .get(\"inputdims\", 0)\n",
    "                     ).rename(\"elements\", \"seqlen\")\n",
    "      # Forward\n",
    "      predictions = model(text, aa_compress(target))\n",
    "      # Mask all outputs that don't work\n",
    "      mask_bad_codons = ntorch.tensor(mask_tbl[target.values], \n",
    "                         names=(\"seqlen\", \"batch\", \"vocablen\")).float()\n",
    "      predictions = (mask_bad_codons.double() + predictions.double())\n",
    "      \n",
    "      \n",
    "     \n",
    "      # Stack the predictions into one long vector\n",
    "#       predictions = predictions.stack(dims=(\"batch\", \"seqlen\"), name=\"seqlen\")\n",
    "\n",
    "      predictions = predictions.argmax(\"vocablen\").index_select(\"seqlen\", \n",
    "                                                                prop_indices)\n",
    "      stacked_target = stacked_target.index_select(\"seqlen\", prop_indices)\n",
    "      \n",
    "#       prediction_list.append(predictions)\n",
    "#       target_list.append(stacked_target)\n",
    "      \n",
    "      num_correct += (predictions == stacked_target).sum().item()   \n",
    "      num_total += predictions.shape[\"seqlen\"]\n",
    "      \n",
    "      # For quick results, toggle this\n",
    "#       if i == 20: \n",
    "#         break\n",
    "      \n",
    "#   return num_correct / num_total \n",
    "\n",
    "  return (prediction_list, target_list, num_correct / num_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "usDAswEJHBhc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vdYGx7hPn3N3"
   },
   "source": [
    "## MISC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zSCQ7JLmo6bR"
   },
   "source": [
    "#### Positional encoding\n",
    "\n",
    "Sasha suggested that this doesn't  matter because RNN's should be able to count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "275u-tVRT6wn"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(ntorch.nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = ntorch.nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        # Keep in log space\n",
    "        div_term = (torch.arange(0, d_model, 2).float() *\n",
    "                             -(math.log(10000.0) / d_model)).exp()\n",
    "        \n",
    "\n",
    "        pe[:, 0::2] = (position * div_term).sin()\n",
    "        pe[:, 1::2] = (position * div_term[:int(d_model /2)]).cos()\n",
    "        pe = pe.unsqueeze(0)\n",
    "        pe = ntorch.tensor(pe, names=(\"batch\", \"seqlen\", \"hiddendim\"))\n",
    "        self.pe = pe.to(device)\n",
    "    def forward(self, embed_seq):\n",
    "        embed_seq = embed_seq.float() + self.pe[\n",
    "                {\"batch\": 0,\"seqlen\" : slice(0,embed_seq.shape[\"seqlen\"])}\n",
    "            ]\n",
    "        return self.dropout(embed_seq)\n",
    "\n",
    "# pe = PositionalEncoding(d_model=23, dropout=0.1).to(device)\n",
    "# print(batch.sequence.shape['seqlen'])\n",
    "# print(embed(batch.sequence).rename(\"onehot\", \"hiddendim\").shape)\n",
    "# pe(batch.sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQuYrDgHUEAN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DownstreamTests_LanguageModel.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
